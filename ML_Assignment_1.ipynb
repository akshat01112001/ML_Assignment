{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshat01112001/ML_Assignment/blob/main/ML_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialisation"
      ],
      "metadata": {
        "id": "98YnZJMBxMxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Necessary Libraries"
      ],
      "metadata": {
        "id": "lumaeTmjd0zt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsH4BjGQcWvM"
      },
      "outputs": [],
      "source": [
        "# Done by\n",
        "# 2019B1A31551H Deepak Gouni\n",
        "# 2020A8PS1162H Srikanth Mangipudi\n",
        "# 2020A7PS0034H Akshat Kumar\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Dataset"
      ],
      "metadata": {
        "id": "TG9Crn9Wd5v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Dsata Set for Assignment 1.csv')"
      ],
      "metadata": {
        "id": "Aia900vzc96q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "kCPxlK8Cu-Tj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deletion of NaN Values"
      ],
      "metadata": {
        "id": "cWS9mEkU6BwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "qM1qS6246FIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Missing Values"
      ],
      "metadata": {
        "id": "pNam_MVKZJDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "88-fc407d8Zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88967432-c272-487d-e53e-77fc9883799f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                         0\n",
              "diagnosis                  0\n",
              "radius_mean                1\n",
              "texture_mean               0\n",
              "perimeter_mean             1\n",
              "area_mean                  0\n",
              "smoothness_mean            0\n",
              "compactness_mean           0\n",
              "concavity_mean             1\n",
              "concave points_mean        0\n",
              "symmetry_mean              0\n",
              "fractal_dimension_mean     0\n",
              "radius_se                  0\n",
              "texture_se                 0\n",
              "perimeter_se               0\n",
              "area_se                    0\n",
              "smoothness_se              0\n",
              "compactness_se             1\n",
              "concavity_se               0\n",
              "concave points_se          0\n",
              "symmetry_se                0\n",
              "fractal_dimension_se       0\n",
              "radius_worst               0\n",
              "texture_worst              0\n",
              "perimeter_worst            0\n",
              "area_worst                 2\n",
              "smoothness_worst           0\n",
              "compactness_worst          0\n",
              "concavity_worst            1\n",
              "concave points_worst       0\n",
              "symmetry_worst             0\n",
              "fractal_dimension_worst    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['radius_mean'].fillna(np.mean(df['radius_mean']),inplace = True)"
      ],
      "metadata": {
        "id": "7FdIgK4jfoUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['perimeter_mean'].fillna(np.mean(df['perimeter_mean']),inplace = True)"
      ],
      "metadata": {
        "id": "Sbhaq4y_gcs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['concavity_mean'].fillna(np.mean(df['concavity_mean']),inplace = True)"
      ],
      "metadata": {
        "id": "VS2QAKjJg4pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['compactness_se'].fillna(np.mean(df['compactness_se']),inplace = True)"
      ],
      "metadata": {
        "id": "h_fBbap7g_Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['area_worst'].fillna(np.mean(df['area_worst']),inplace = True)"
      ],
      "metadata": {
        "id": "Bbqn1_zHhJnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['concavity_worst'].fillna(np.mean(df['concavity_worst']),inplace = True)"
      ],
      "metadata": {
        "id": "U1-ZT2UIhSD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRWkbS1anp0f",
        "outputId": "843f3c8a-4c69-44fe-a559-ed656b5d44dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                         0\n",
              "diagnosis                  0\n",
              "radius_mean                0\n",
              "texture_mean               0\n",
              "perimeter_mean             0\n",
              "area_mean                  0\n",
              "smoothness_mean            0\n",
              "compactness_mean           0\n",
              "concavity_mean             0\n",
              "concave points_mean        0\n",
              "symmetry_mean              0\n",
              "fractal_dimension_mean     0\n",
              "radius_se                  0\n",
              "texture_se                 0\n",
              "perimeter_se               0\n",
              "area_se                    0\n",
              "smoothness_se              0\n",
              "compactness_se             0\n",
              "concavity_se               0\n",
              "concave points_se          0\n",
              "symmetry_se                0\n",
              "fractal_dimension_se       0\n",
              "radius_worst               0\n",
              "texture_worst              0\n",
              "perimeter_worst            0\n",
              "area_worst                 0\n",
              "smoothness_worst           0\n",
              "compactness_worst          0\n",
              "concavity_worst            0\n",
              "concave points_worst       0\n",
              "symmetry_worst             0\n",
              "fractal_dimension_worst    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standard Score (Z-Score) Conversion"
      ],
      "metadata": {
        "id": "R9ZSl5UFZNR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Z-score conversion\n",
        "for column in df.columns:\n",
        "  if(column=='diagnosis' or column=='id'):\n",
        "    continue\n",
        "  mean = np.mean(df[column])\n",
        "  std_dev = np.std(df[column])\n",
        "  df[column] = np.divide(np.subtract(df[column], mean), std_dev)\n",
        "\n",
        "# Separation of features and label\n",
        "X = df.drop(['diagnosis','id'],axis=1).values\n",
        "y = df['diagnosis'].values\n",
        "\n",
        "# Splitting of dataset in training set and test set\n",
        "test_size = 0.33\n",
        "n_samples = X.shape[0]\n",
        "test_idx = np.random.choice(n_samples, int(n_samples * test_size), replace=False) # randomly select test indices\n",
        "train_idx = np.setdiff1d(np.arange(n_samples), test_idx) # use remaining indices for training\n",
        "X_train, X_test = X[train_idx], X[test_idx] # split features into training and test sets\n",
        "y_train, y_test = y[train_idx], y[test_idx] # split labels into training and test sets"
      ],
      "metadata": {
        "id": "Xekgh7GIjkc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label Encoding and Dataset Splitting"
      ],
      "metadata": {
        "id": "hImpyZU6vk4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label encoding of diagnosis\n",
        "df.loc[df['diagnosis'] == 'M', 'diagnosis'] = 0\n",
        "df.loc[df['diagnosis'] == 'B', 'diagnosis'] = 1\n",
        "\n",
        "# Separation of features and label\n",
        "X = df.drop(['diagnosis','id'],axis=1).values\n",
        "y = df['diagnosis'].values\n",
        "\n",
        "# Splitting of dataset in training set and test set\n",
        "test_size = 0.33\n",
        "n_samples = X.shape[0]\n",
        "test_idx = np.random.choice(n_samples, int(n_samples * test_size), replace=False) # randomly select test indices\n",
        "train_idx = np.setdiff1d(np.arange(n_samples), test_idx) # use remaining indices for training\n",
        "X_train, X_test = X[train_idx], X[test_idx] # split features into training and test sets\n",
        "y_train, y_test = y[train_idx], y[test_idx] # split labels into training and test sets"
      ],
      "metadata": {
        "id": "ATCM4RJzpT3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part A - Perceptron Learning Algorithm"
      ],
      "metadata": {
        "id": "luh2h6_0vTEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perception class"
      ],
      "metadata": {
        "id": "OsAAkGFvvuOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "    def __init__(self, learning_rate=0.1, max_iter=1000, random_state=None):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_iter = max_iter\n",
        "        self.random_state = random_state\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        # Set random seed\n",
        "        if self.random_state is not None:\n",
        "            random.seed(self.random_state)\n",
        "        \n",
        "        # Initialize weights and bias\n",
        "        self.w = np.array([random.random() for i in range(X.shape[1])])\n",
        "        self.b = random.random()\n",
        "        \n",
        "        # Train the perceptron\n",
        "        for i in range(self.max_iter):\n",
        "            for xi, yi in zip(X, y):\n",
        "                if yi * (np.dot(xi, self.w) + self.b) <= 0:\n",
        "                    self.w += self.learning_rate * yi * xi\n",
        "                    self.b += self.learning_rate * yi\n",
        "    \n",
        "    def predict(self, X):\n",
        "        return np.sign(np.dot(X, self.w) + self.b)"
      ],
      "metadata": {
        "id": "mi9-gFBNmNOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perceptron Model - PM1"
      ],
      "metadata": {
        "id": "hW0zIOQmv1ZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Fitting and Prediction"
      ],
      "metadata": {
        "id": "-buDLW1fxEHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of iterations\n",
        "num_iterations = 10\n",
        "\n",
        "# Create an empty array to store the accuracy results\n",
        "acc_results = np.zeros(num_iterations)\n",
        "\n",
        "# Create empty arrays to store precision and recall scores\n",
        "precision_scores = np.zeros(num_iterations)\n",
        "recall_scores = np.zeros(num_iterations)\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    # Separation of features and label\n",
        "    X = df.drop(['diagnosis','id'],axis=1).values\n",
        "    y = df['diagnosis'].values\n",
        "\n",
        "    # Splitting of dataset in training set and test set\n",
        "    test_size = 0.33\n",
        "    n_samples = X.shape[0]\n",
        "    test_idx = np.random.choice(n_samples, int(n_samples * test_size), replace=False) # randomly select test indices\n",
        "    train_idx = np.setdiff1d(np.arange(n_samples), test_idx) # use remaining indices for training\n",
        "    X_train, X_test = X[train_idx], X[test_idx] # split features into training and test sets\n",
        "    y_train, y_test = y[train_idx], y[test_idx] # split labels into training and test sets\n",
        "    \n",
        "    # Create a Perceptron model\n",
        "    pm1 = Perceptron()\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    pm1.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = pm1.predict(X_test)\n",
        "    y_pred[y_pred == -1] = 0\n",
        "\n",
        "    # Calculate the accuracy of the model\n",
        "    pm1_acc = np.mean(y_pred == y_test)\n",
        "    acc_results[i] = pm1_acc\n",
        "    print(f\"PM1 accuracy for iteration {i+1}: {pm1_acc}\")\n",
        "\n",
        "    # Calculate the precision and recall scores\n",
        "    true_positives = np.sum((y_test == 1) & (y_pred == 1))\n",
        "    false_positives = np.sum((y_test == 0) & (y_pred == 1))\n",
        "    false_negatives = np.sum((y_test == 1) & (y_pred == 0))\n",
        "\n",
        "    precision_scores[i] = true_positives / (true_positives + false_positives)\n",
        "    recall_scores[i] = true_positives / (true_positives + false_negatives)\n",
        "\n",
        "# Calculate the mean, variance, precision, and recall of the accuracy results\n",
        "mean_acc = np.mean(acc_results)\n",
        "acc_var = np.var(acc_results)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "\n",
        "# Print the final results\n",
        "print(f\"Average PM1 accuracy over {num_iterations} iterations: {mean_acc}\")\n",
        "print(f\"Variance of PM1 accuracy over {num_iterations} iterations: {acc_var}\")\n",
        "print(f\"Mean precision score of PM1 over {num_iterations} iterations: {mean_precision}\")\n",
        "print(f\"Mean recall score of PM1 over {num_iterations} iterations: {mean_recall}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNkTjtlhqHSJ",
        "outputId": "87f00196-31dd-4975-d2e5-0ed35c160f6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PM1 accuracy for iteration 1: 0.572972972972973\n",
            "PM1 accuracy for iteration 2: 0.6270270270270271\n",
            "PM1 accuracy for iteration 3: 0.6378378378378379\n",
            "PM1 accuracy for iteration 4: 0.6432432432432432\n",
            "PM1 accuracy for iteration 5: 0.654054054054054\n",
            "PM1 accuracy for iteration 6: 0.5783783783783784\n",
            "PM1 accuracy for iteration 7: 0.5891891891891892\n",
            "PM1 accuracy for iteration 8: 0.6486486486486487\n",
            "PM1 accuracy for iteration 9: 0.654054054054054\n",
            "PM1 accuracy for iteration 10: 0.654054054054054\n",
            "Average PM1 accuracy over 10 iterations: 0.625945945945946\n",
            "Variance of PM1 accuracy over 10 iterations: 0.0009747260774287799\n",
            "Mean precision score of PM1 over 10 iterations: 0.625945945945946\n",
            "Mean recall score of PM1 over 10 iterations: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perceptron Model - PM2"
      ],
      "metadata": {
        "id": "2AreGstNv_nc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Fitting and Prediction"
      ],
      "metadata": {
        "id": "ulJg-zmgxBQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of iterations\n",
        "num_iterations = 10\n",
        "\n",
        "# Create an empty array to store the accuracy results\n",
        "acc_results = np.zeros(num_iterations)\n",
        "\n",
        "# Create empty arrays to store precision and recall scores\n",
        "precision_scores = np.zeros(num_iterations)\n",
        "recall_scores = np.zeros(num_iterations)\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    # Separation of features and label\n",
        "    X = df.drop(['diagnosis','id'],axis=1).values\n",
        "    y = df['diagnosis'].values\n",
        "\n",
        "    # Splitting of dataset in training set and test set\n",
        "    test_size = 0.33\n",
        "    n_samples = X.shape[0]\n",
        "    test_idx = np.random.choice(n_samples, int(n_samples * test_size), replace=False) # randomly select test indices\n",
        "    train_idx = np.setdiff1d(np.arange(n_samples), test_idx) # use remaining indices for training\n",
        "    X_train, X_test = X[train_idx], X[test_idx] # split features into training and test sets\n",
        "    y_train, y_test = y[train_idx], y[test_idx] # split labels into training and test sets\n",
        "    \n",
        "    # Create a Perceptron model\n",
        "    pm2 = Perceptron()\n",
        "\n",
        "    # Fit the model to the training data (with reversed order)\n",
        "    pm2.fit(X_train[::-1], y_train[::-1])\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = pm2.predict(X_test)\n",
        "    y_pred[y_pred == -1] = 0\n",
        "\n",
        "    # Calculate the accuracy of the model\n",
        "    pm2_acc = np.mean(y_pred == y_test)\n",
        "    acc_results[i] = pm2_acc\n",
        "    print(f\"PM2 accuracy for iteration {i+1}: {pm2_acc}\")\n",
        "\n",
        "    # Calculate the precision and recall scores\n",
        "    true_positives = np.sum((y_test == 1) & (y_pred == 1))\n",
        "    false_positives = np.sum((y_test == 0) & (y_pred == 1))\n",
        "    false_negatives = np.sum((y_test == 1) & (y_pred == 0))\n",
        "\n",
        "    precision_scores[i] = true_positives / (true_positives + false_positives)\n",
        "    recall_scores[i] = true_positives / (true_positives + false_negatives)\n",
        "\n",
        "# Calculate the mean, variance, precision, and recall of the accuracy results\n",
        "mean_acc = np.mean(acc_results)\n",
        "acc_var = np.var(acc_results)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "\n",
        "# Print the final results\n",
        "print(f\"Average PM2 accuracy over {num_iterations} iterations: {mean_acc}\")\n",
        "print(f\"Variance of PM2 accuracy over {num_iterations} iterations: {acc_var}\")\n",
        "print(f\"Mean precision score of PM2 over {num_iterations} iterations: {mean_precision}\")\n",
        "print(f\"Mean recall score of PM2 over {num_iterations} iterations: {mean_recall}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9K8fDSp1KO9",
        "outputId": "c68b4cf7-6ebb-4489-ac11-3b69bf0a3714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PM2 accuracy for iteration 1: 0.6594594594594595\n",
            "PM2 accuracy for iteration 2: 0.6270270270270271\n",
            "PM2 accuracy for iteration 3: 0.6486486486486487\n",
            "PM2 accuracy for iteration 4: 0.6054054054054054\n",
            "PM2 accuracy for iteration 5: 0.5837837837837838\n",
            "PM2 accuracy for iteration 6: 0.6594594594594595\n",
            "PM2 accuracy for iteration 7: 0.6378378378378379\n",
            "PM2 accuracy for iteration 8: 0.6378378378378379\n",
            "PM2 accuracy for iteration 9: 0.6702702702702703\n",
            "PM2 accuracy for iteration 10: 0.5837837837837838\n",
            "Average PM2 accuracy over 10 iterations: 0.6313513513513513\n",
            "Variance of PM2 accuracy over 10 iterations: 0.0008695398100803508\n",
            "Mean precision score of PM2 over 10 iterations: 0.6313513513513513\n",
            "Mean recall score of PM2 over 10 iterations: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perceptron Model - PM3"
      ],
      "metadata": {
        "id": "pf5E0xmfwC2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Fitting and Prediction\n"
      ],
      "metadata": {
        "id": "dpQl5cxCwY7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of iterations\n",
        "num_iterations = 10\n",
        "\n",
        "# Create an empty array to store the accuracy results\n",
        "acc_results = np.zeros(num_iterations)\n",
        "\n",
        "# Create empty arrays to store precision and recall scores\n",
        "precision_scores = np.zeros(num_iterations)\n",
        "recall_scores = np.zeros(num_iterations)\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    # Separation of features and label\n",
        "    X = df.drop(['diagnosis','id'],axis=1).values\n",
        "    y = df['diagnosis'].values\n",
        "\n",
        "    # Splitting of dataset in training set and test set\n",
        "    test_size = 0.33\n",
        "    n_samples = X.shape[0]\n",
        "    test_idx = np.random.choice(n_samples, int(n_samples * test_size), replace=False) # randomly select test indices\n",
        "    train_idx = np.setdiff1d(np.arange(n_samples), test_idx) # use remaining indices for training\n",
        "    X_train, X_test = X[train_idx], X[test_idx] # split features into training and test sets\n",
        "    y_train, y_test = y[train_idx], y[test_idx] # split labels into training and test sets\n",
        "    \n",
        "    # Create a Perceptron model\n",
        "    pm3 = Perceptron()\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    pm3.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = pm3.predict(X_test)\n",
        "    y_pred[y_pred == -1] = 0\n",
        "\n",
        "    # Calculate the accuracy of the model\n",
        "    pm3_acc = np.mean(y_pred == y_test)\n",
        "    acc_results[i] = pm3_acc\n",
        "    print(f\"PM3 accuracy for iteration {i+1}: {pm3_acc}\")\n",
        "\n",
        "    # Calculate the precision and recall scores\n",
        "    true_positives = np.sum((y_test == 1) & (y_pred == 1))\n",
        "    false_positives = np.sum((y_test == 0) & (y_pred == 1))\n",
        "    false_negatives = np.sum((y_test == 1) & (y_pred == 0))\n",
        "\n",
        "    precision_scores[i] = true_positives / (true_positives + false_positives)\n",
        "    recall_scores[i] = true_positives / (true_positives + false_negatives)\n",
        "\n",
        "# Calculate the mean, variance, precision, and recall of the accuracy results\n",
        "mean_acc = np.mean(acc_results)\n",
        "acc_var = np.var(acc_results)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "\n",
        "# Print the final results\n",
        "print(f\"Average PM3 accuracy over {num_iterations} iterations: {mean_acc}\")\n",
        "print(f\"Variance of PM3 accuracy over {num_iterations} iterations: {acc_var}\")\n",
        "print(f\"Mean precision score of PM3 over {num_iterations} iterations: {mean_precision}\")\n",
        "print(f\"Mean recall score of PM3 over {num_iterations} iterations: {mean_recall}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvNjsWwc8297",
        "outputId": "b3e5f005-5c73-44f7-9c29-20241a23e27f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PM3 accuracy for iteration 1: 0.8648648648648649\n",
            "PM3 accuracy for iteration 2: 0.7783783783783784\n",
            "PM3 accuracy for iteration 3: 0.7243243243243244\n",
            "PM3 accuracy for iteration 4: 0.745945945945946\n",
            "PM3 accuracy for iteration 5: 0.772972972972973\n",
            "PM3 accuracy for iteration 6: 0.8162162162162162\n",
            "PM3 accuracy for iteration 7: 0.918918918918919\n",
            "PM3 accuracy for iteration 8: 0.9459459459459459\n",
            "PM3 accuracy for iteration 9: 0.7891891891891892\n",
            "PM3 accuracy for iteration 10: 0.8162162162162162\n",
            "Average PM3 accuracy over 10 iterations: 0.8172972972972973\n",
            "Variance of PM3 accuracy over 10 iterations: 0.004714682249817385\n",
            "Mean precision score of PM3 over 10 iterations: 0.7841382135359278\n",
            "Mean recall score of PM3 over 10 iterations: 0.998326330532213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perceptron Model - PM4"
      ],
      "metadata": {
        "id": "0CbFjMKrwo4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Randomisation of Features"
      ],
      "metadata": {
        "id": "3apcAdkMwxf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomize the order of the features\n",
        "cols = list(df.columns)\n",
        "np.random.shuffle(cols)\n",
        "\n",
        "# use the shuffled list of column names to reorder the DataFrame\n",
        "df = df[cols]\n",
        "X = df.drop(['diagnosis','id'],axis=1).values\n",
        "y = df['diagnosis'].values\n",
        "\n",
        "# Splitting of dataset in training set and test set\n",
        "test_size = 0.33\n",
        "n_samples = X.shape[0]\n",
        "test_idx = np.random.choice(n_samples, int(n_samples * test_size), replace=False) # randomly select test indices\n",
        "train_idx = np.setdiff1d(np.arange(n_samples), test_idx) # use remaining indices for training\n",
        "X_train, X_test = X[train_idx], X[test_idx] # split features into training and test sets\n",
        "y_train, y_test = y[train_idx], y[test_idx] # split labels into training and test sets"
      ],
      "metadata": {
        "id": "AzSQ3LIDE0Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Fitting and Prediction"
      ],
      "metadata": {
        "id": "tDJOZ0IZw1eY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y[test_idx] # split labels into training and test sets\n",
        "    # Define the number of iterations\n",
        "num_iterations = 10\n",
        "\n",
        "# Create an empty array to store the accuracy results\n",
        "acc_results = np.zeros(num_iterations)\n",
        "\n",
        "# Create empty arrays to store precision and recall scores\n",
        "precision_scores = np.zeros(num_iterations)\n",
        "recall_scores = np.zeros(num_iterations)\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    # Separation of features and label\n",
        "    X = df.drop(['diagnosis','id'],axis=1).values\n",
        "    y = df['diagnosis'].values\n",
        "\n",
        "    # Splitting of dataset in training set and test set\n",
        "    test_size = 0.33\n",
        "    n_samples = X.shape[0]\n",
        "    test_idx = np.random.choice(n_samples, int(n_samples * test_size), replace=False) # randomly select test indices\n",
        "    train_idx = np.setdiff1d(np.arange(n_samples), test_idx) # use remaining indices for training\n",
        "    X_train, X_test = X[train_idx], X[test_idx] # split features into training and test sets\n",
        "    y_train, y_test = y[train_idx], \n",
        "    # Create a Perceptron model\n",
        "    pm4 = Perceptron()\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    pm4.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = pm4.predict(X_test)\n",
        "    y_pred[y_pred == -1] = 0\n",
        "\n",
        "    # Calculate the accuracy of the model\n",
        "    pm4_acc = np.mean(y_pred == y_test)\n",
        "    acc_results[i] = pm4_acc\n",
        "    print(f\"PM4 accuracy for iteration {i+1}: {pm4_acc}\")\n",
        "\n",
        "    # Calculate the precision and recall scores\n",
        "    true_positives = np.sum((y_test == 1) & (y_pred == 1))\n",
        "    false_positives = np.sum((y_test == 0) & (y_pred == 1))\n",
        "    false_negatives = np.sum((y_test == 1) & (y_pred == 0))\n",
        "\n",
        "    precision_scores[i] = true_positives / (true_positives + false_positives)\n",
        "    recall_scores[i] = true_positives / (true_positives + false_negatives)\n",
        "\n",
        "# Calculate the mean, variance, precision, and recall of the accuracy results\n",
        "mean_acc = np.mean(acc_results)\n",
        "acc_var = np.var(acc_results)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "\n",
        "# Print the final results\n",
        "print(f\"Average PM4 accuracy over {num_iterations} iterations: {mean_acc}\")\n",
        "print(f\"Variance of PM4 accuracy over {num_iterations} iterations: {acc_var}\")\n",
        "print(f\"Mean precision score of PM4 over {num_iterations} iterations: {mean_precision}\")\n",
        "print(f\"Mean recall score of PM4 over {num_iterations} iterations: {mean_recall}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddaafb2c-6574-41a9-eec1-49b4009c1ad7",
        "id": "i8n5a_c7Vrn9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PM4 accuracy for iteration 1: 0.7647058823529411\n",
            "PM4 accuracy for iteration 2: 0.9037433155080213\n",
            "PM4 accuracy for iteration 3: 0.8181818181818182\n",
            "PM4 accuracy for iteration 4: 0.8181818181818182\n",
            "PM4 accuracy for iteration 5: 0.8074866310160428\n",
            "PM4 accuracy for iteration 6: 0.786096256684492\n",
            "PM4 accuracy for iteration 7: 0.839572192513369\n",
            "PM4 accuracy for iteration 8: 0.7914438502673797\n",
            "PM4 accuracy for iteration 9: 0.8609625668449198\n",
            "PM4 accuracy for iteration 10: 0.8235294117647058\n",
            "Average PM4 accuracy over 10 iterations: 0.8213903743315509\n",
            "Variance of PM4 accuracy over 10 iterations: 0.001425262375246646\n",
            "Mean precision score of PM4 over 10 iterations: 0.7778004337426032\n",
            "Mean recall score of PM4 over 10 iterations: 0.995582298136646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part B – Fisher’s Linear Discriminant Analysis"
      ],
      "metadata": {
        "id": "Hz4JGaOJyjsU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fisher’s linear discriminant model (FLDM1)"
      ],
      "metadata": {
        "id": "wmimnZDX14IP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute class means and scatter matrices of Negative and Positive classes\n",
        "mean1 = np.mean(X_train[y_train==0], axis=0)\n",
        "mean2 = np.mean(X_train[y_train==1], axis=0)\n",
        "\n",
        "# Variance of Negative and Positive classes\n",
        "S1 = (X_train[y_train==0] - mean1).T.dot(X_train[y_train==0] - mean1)\n",
        "S2 = (X_train[y_train==1] - mean2).T.dot(X_train[y_train==1] - mean2)\n",
        "Sw = S1 + S2 \n",
        "Sb = np.outer(mean2 - mean1, mean2 - mean1) \n",
        "\n",
        "# Compute eigenvectors and eigenvalues of Sw^-1*Sb\n",
        "A = np.linalg.inv(Sw).dot(Sb)\n",
        "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
        "eigenvectors = eigenvectors[:, np.argsort(eigenvalues)[::-1]]\n",
        "w = eigenvectors[:, 0:2]\n",
        "\n",
        "# Project data onto 2D using w\n",
        "X_lda = X_test.dot(w)\n",
        "\n",
        "# Compute decision boundary\n",
        "threshold1 = (mean1.dot(w[:, 0]) + mean2.dot(w[:, 0])) / 2\n",
        "\n",
        "# Plot data points and decision boundary\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(X_lda[y_test==0, 0], X_lda[y_test==0, 1], label='Negative Class', alpha=0.5)\n",
        "ax.scatter(X_lda[y_test==1, 0], X_lda[y_test==1, 1], label='Positive Class', alpha=0.5)\n",
        "ax.plot([threshold1, threshold1], [np.min(X_lda[:, 1]), np.max(X_lda[:, 1])], color='k', linestyle='--', label='Boundary')\n",
        "ax.set_xlabel('LD1')\n",
        "ax.set_ylabel('LD2')\n",
        "ax.set_title('Linear Discriminant Analysis')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "0l4PY3oxEf0C",
        "outputId": "ef546c85-f1d2-467b-ccc6-4ec2209a1cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fisher’s linear discriminant model (FLDM2)"
      ],
      "metadata": {
        "id": "BbhwKBTj2F9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomize the order of the features\n",
        "cols = list(df.columns)\n",
        "np.random.shuffle(cols)\n",
        "\n",
        "# use the shuffled list of column names to reorder the DataFrame\n",
        "df = df[cols]\n",
        "X = df.drop(['diagnosis','id'],axis=1).values\n",
        "y = df['diagnosis'].values\n",
        "\n",
        "# Splitting of dataset in training set and test set\n",
        "test_size = 0.33\n",
        "n_samples = X.shape[0]\n",
        "test_idx = np.random.choice(n_samples, int(n_samples * test_size), replace=False) # randomly select test indices\n",
        "train_idx = np.setdiff1d(np.arange(n_samples), test_idx) # use remaining indices for training\n",
        "X_train, X_test = X[train_idx], X[test_idx] # split features into training and test sets\n",
        "y_train, y_test = y[train_idx], y[test_idx] # split labels into training and test sets\n",
        "\n",
        "# Randomize the order of the features\n",
        "train_X_permuted = np.random.permutation(X_train)\n",
        "test_X_permuted = np.random.permutation(X_test)\n",
        "\n",
        "# Compute class means and scatter matrices\n",
        "mean1 = np.mean(X_train[y_train==0], axis=0)\n",
        "mean2 = np.mean(X_train[y_train==1], axis=0)\n",
        "\n",
        "S1 = (train_X_permuted[y_train==0] - mean1).T.dot(train_X_permuted[y_train==0] - mean1)\n",
        "S2 = (train_X_permuted[y_train==1] - mean2).T.dot(train_X_permuted[y_train==1] - mean2)\n",
        "Sw = S1 + S2\n",
        "Sb = np.outer(mean2 - mean1, mean2 - mean1) \n",
        "\n",
        "# Compute eigenvectors and eigenvalues of Sw^-1*Sb\n",
        "A = np.linalg.inv(Sw).dot(Sb)\n",
        "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
        "eigenvectors = eigenvectors[:, np.argsort(eigenvalues)[::-1]]\n",
        "w = eigenvectors[:, 0:2]\n",
        "\n",
        "# Project data onto 2D using w\n",
        "X_lda = test_X_permuted.dot(w)\n",
        "\n",
        "# Compute decision boundary\n",
        "threshold1 = (mean1.dot(w[:, 0]) + mean2.dot(w[:, 0])) / 2\n",
        "\n",
        "# Plot data points and decision boundary\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(X_lda[y_test==0, 0], X_lda[y_test==0, 1], label='Negative Class', alpha=0.5)\n",
        "ax.scatter(X_lda[y_test==1, 0], X_lda[y_test==1, 1], label='Positive Class', alpha=0.5)\n",
        "ax.plot([threshold1, threshold1], [np.min(X_lda[:, 1]), np.max(X_lda[:, 1])], color='k', linestyle='--', label='Boundary')\n",
        "ax.set_xlabel('LD1')\n",
        "ax.set_ylabel('LD2')\n",
        "ax.set_title('Linear Discriminant Analysis')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "D8Bx8Lll05gH",
        "outputId": "8fce95c1-2437-43f5-91b1-99f8c4a48481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/matplotlib/collections.py:192: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  offsets = np.asanyarray(offsets, float)\n",
            "/usr/local/lib/python3.9/dist-packages/matplotlib/cbook/__init__.py:1335: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  return np.asarray(x, float)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part C – Logistic Regression"
      ],
      "metadata": {
        "id": "5nzcXNx23D61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression Class"
      ],
      "metadata": {
        "id": "QoyQYYXlcFcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, alpha=0.01, iterations=1000, batch_size=32):\n",
        "        self.alpha = alpha\n",
        "        self.iterations = iterations\n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def cost_function(self, X, y, theta):\n",
        "        m = len(y)\n",
        "        h = self.sigmoid(X.dot(theta))\n",
        "        J = (-1/m) * (y.T.dot(np.log(h)) + (1-y).T.dot(np.log(1-h)))\n",
        "        return J\n",
        "\n",
        "    def batch_gradient_descent(self, X, y):\n",
        "        m, n = X.shape\n",
        "        theta = np.zeros(n)\n",
        "        cost_history = []\n",
        "        for i in range(self.iterations):\n",
        "            for j in range(0, m, self.batch_size):\n",
        "                X_batch = X[j:j+self.batch_size]\n",
        "                y_batch = y[j:j+self.batch_size]\n",
        "                h = self.sigmoid(X_batch.dot(theta))\n",
        "                theta = theta - self.alpha * (1/self.batch_size) * X_batch.T.dot(h-y_batch)\n",
        "                cost_history.append(self.cost_function(X_batch, y_batch, theta))\n",
        "        return theta, cost_history\n",
        "\n",
        "    def mini_batch_gradient_descent(self, X, y):\n",
        "        m, n = X.shape\n",
        "        theta = np.zeros(n)\n",
        "        cost_history = []\n",
        "        for i in range(self.iterations):\n",
        "            permutation = np.random.permutation(m)\n",
        "            X_permuted = X[permutation]\n",
        "            y_permuted = y[permutation]\n",
        "            for j in range(0, m, self.batch_size):\n",
        "                X_batch = X_permuted[j:j+self.batch_size]\n",
        "                y_batch = y_permuted[j:j+self.batch_size]\n",
        "                h = self.sigmoid(X_batch.dot(theta))\n",
        "                theta = theta - self.alpha * (1/self.batch_size) * X_batch.T.dot(h-y_batch)\n",
        "                cost_history.append(self.cost_function(X_batch, y_batch, theta))\n",
        "        return theta, cost_history\n",
        "\n",
        "    def stochastic_gradient_descent(self, X, y):\n",
        "        m, n = X.shape\n",
        "        theta = np.zeros(n)\n",
        "        cost_history = []\n",
        "        for i in range(self.iterations):\n",
        "            permutation = np.random.permutation(m)\n",
        "            X_permuted = X[permutation]\n",
        "            y_permuted = y[permutation]\n",
        "            for j in range(m):\n",
        "                x_j = X_permuted[j:]\n",
        "                y_j = y_permuted[j:]\n",
        "                h = self.sigmoid(x_j.dot(theta))\n",
        "                theta = theta - self.alpha * (1/m) * x_j.T.dot(h-y_j)\n",
        "                cost_history.append(self.cost_function(x_j, y_j, theta))\n",
        "        return theta, cost_history\n",
        "\n",
        "    def predict(self, X, theta, threshold=0.5):\n",
        "        h = self.sigmoid(X.dot(theta))\n",
        "        return (h >= threshold).astype(int)"
      ],
      "metadata": {
        "id": "7jk-VCBIb17k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bias Term Addition"
      ],
      "metadata": {
        "id": "eBhtqJtccBqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.column_stack((np.ones(len(X)), X))\n",
        "\n",
        "# Splitting of dataset in training set and test set\n",
        "test_size = 0.33\n",
        "n_samples = X.shape[0]\n",
        "test_idx = np.random.choice(n_samples, int(n_samples * test_size), replace=False) # randomly select test indices\n",
        "train_idx = np.setdiff1d(np.arange(n_samples), test_idx) # use remaining indices for training\n",
        "X_train, X_test = X[train_idx], X[test_idx] # split features into training and test sets\n",
        "y_train, y_test = y[train_idx], y[test_idx] # split labels into training and test sets"
      ],
      "metadata": {
        "id": "FtyxoGbU1SZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LR1"
      ],
      "metadata": {
        "id": "0XPx4JjGcMJa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch Gradient Descent With Different Learning Rates (Alpha)"
      ],
      "metadata": {
        "id": "Pm1TzdcYRQ6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = np.zeros((10, 5))\n",
        "precisions = np.zeros((10, 5))\n",
        "recalls = np.zeros((10, 5))\n",
        "\n",
        "for i in range(10):\n",
        "    lr1 = LogisticRegression(alpha=0.01)\n",
        "    theta1, cost_history1 = lr1.batch_gradient_descent(X.astype(float), y.astype(float))\n",
        "    thresholds = [0.5, 0.3, 0.4, 0.6, 0.7]\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = lr1.predict(X, theta1, threshold=threshold)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        precision = np.sum((y_pred == 1) & (y == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y == 1)) / np.sum(y == 1)\n",
        "        accuracies[i, j] = accuracy\n",
        "        precisions[i, j] = precision\n",
        "        recalls[i, j] = recall\n",
        "        print(f\"Iteration {i+1}, LR1 with threshold {threshold}: Accuracy = {accuracy:.3f}, Precision = {precision:.3f}, Recall = {recall:.3f}\")\n",
        "\n",
        "print(f\"Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(accuracies, axis=0)}\")\n",
        "print(f\"Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(precisions, axis=0)}\")\n",
        "print(f\"Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(recalls, axis=0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6UZpcZRb5Hj",
        "outputId": "9087a418-8588-4c22-99e9-ccc0d3cb5cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-7bdc6e4aa47a>:8: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n",
            "<ipython-input-5-7bdc6e4aa47a>:13: RuntimeWarning: divide by zero encountered in log\n",
            "  J = (-1/m) * (y.T.dot(np.log(h)) + (1-y).T.dot(np.log(1-h)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, LR1 with threshold 0.5: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 1, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 1, LR1 with threshold 0.4: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 1, LR1 with threshold 0.6: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 1, LR1 with threshold 0.7: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 2, LR1 with threshold 0.5: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 2, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 2, LR1 with threshold 0.4: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 2, LR1 with threshold 0.6: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 2, LR1 with threshold 0.7: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 3, LR1 with threshold 0.5: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 3, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 3, LR1 with threshold 0.4: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 3, LR1 with threshold 0.6: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 3, LR1 with threshold 0.7: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 4, LR1 with threshold 0.5: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 4, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 4, LR1 with threshold 0.4: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 4, LR1 with threshold 0.6: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 4, LR1 with threshold 0.7: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 5, LR1 with threshold 0.5: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 5, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 5, LR1 with threshold 0.4: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 5, LR1 with threshold 0.6: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 5, LR1 with threshold 0.7: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 6, LR1 with threshold 0.5: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 6, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 6, LR1 with threshold 0.4: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 6, LR1 with threshold 0.6: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 6, LR1 with threshold 0.7: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 7, LR1 with threshold 0.5: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 7, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 7, LR1 with threshold 0.4: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 7, LR1 with threshold 0.6: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 7, LR1 with threshold 0.7: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 8, LR1 with threshold 0.5: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 8, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 8, LR1 with threshold 0.4: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 8, LR1 with threshold 0.6: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 8, LR1 with threshold 0.7: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 9, LR1 with threshold 0.5: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 9, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 9, LR1 with threshold 0.4: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 9, LR1 with threshold 0.6: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 9, LR1 with threshold 0.7: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 10, LR1 with threshold 0.5: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 10, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 10, LR1 with threshold 0.4: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 10, LR1 with threshold 0.6: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Iteration 10, LR1 with threshold 0.7: Accuracy = 0.929, Precision = 0.917, Recall = 0.974\n",
            "Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.92895204 0.92895204 0.92895204 0.92895204 0.92895204]\n",
            "Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.9171123 0.9171123 0.9171123 0.9171123 0.9171123]\n",
            "Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.97443182 0.97443182 0.97443182 0.97443182 0.97443182]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = np.zeros((10, 5))\n",
        "precisions = np.zeros((10, 5))\n",
        "recalls = np.zeros((10, 5))\n",
        "\n",
        "for i in range(10):\n",
        "    lr1 = LogisticRegression(alpha=0.001)\n",
        "    theta1, cost_history1 = lr1.batch_gradient_descent(X.astype(float), y.astype(float))\n",
        "    thresholds = [0.5, 0.3, 0.4, 0.6, 0.7]\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = lr1.predict(X, theta1, threshold=threshold)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        precision = np.sum((y_pred == 1) & (y == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y == 1)) / np.sum(y == 1)\n",
        "        accuracies[i, j] = accuracy\n",
        "        precisions[i, j] = precision\n",
        "        recalls[i, j] = recall\n",
        "        print(f\"Iteration {i+1}, LR1 with threshold {threshold}: Accuracy = {accuracy:.3f}, Precision = {precision:.3f}, Recall = {recall:.3f}\")\n",
        "    \n",
        "print(f\"Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(accuracies, axis=0)}\")\n",
        "print(f\"Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(precisions, axis=0)}\")\n",
        "print(f\"Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(recalls, axis=0)}\")"
      ],
      "metadata": {
        "id": "ZnuYjvJk_Nr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecbb306d-cffb-440d-9390-ee90c989c5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-7bdc6e4aa47a>:8: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n",
            "<ipython-input-5-7bdc6e4aa47a>:13: RuntimeWarning: divide by zero encountered in log\n",
            "  J = (-1/m) * (y.T.dot(np.log(h)) + (1-y).T.dot(np.log(1-h)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, LR1 with threshold 0.5: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 1, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.913, Recall = 0.980\n",
            "Iteration 1, LR1 with threshold 0.4: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 1, LR1 with threshold 0.6: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 1, LR1 with threshold 0.7: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 2, LR1 with threshold 0.5: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 2, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.913, Recall = 0.980\n",
            "Iteration 2, LR1 with threshold 0.4: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 2, LR1 with threshold 0.6: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 2, LR1 with threshold 0.7: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 3, LR1 with threshold 0.5: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 3, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.913, Recall = 0.980\n",
            "Iteration 3, LR1 with threshold 0.4: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 3, LR1 with threshold 0.6: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 3, LR1 with threshold 0.7: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 4, LR1 with threshold 0.5: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 4, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.913, Recall = 0.980\n",
            "Iteration 4, LR1 with threshold 0.4: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 4, LR1 with threshold 0.6: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 4, LR1 with threshold 0.7: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 5, LR1 with threshold 0.5: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 5, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.913, Recall = 0.980\n",
            "Iteration 5, LR1 with threshold 0.4: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 5, LR1 with threshold 0.6: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 5, LR1 with threshold 0.7: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 6, LR1 with threshold 0.5: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 6, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.913, Recall = 0.980\n",
            "Iteration 6, LR1 with threshold 0.4: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 6, LR1 with threshold 0.6: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 6, LR1 with threshold 0.7: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 7, LR1 with threshold 0.5: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 7, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.913, Recall = 0.980\n",
            "Iteration 7, LR1 with threshold 0.4: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 7, LR1 with threshold 0.6: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 7, LR1 with threshold 0.7: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 8, LR1 with threshold 0.5: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 8, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.913, Recall = 0.980\n",
            "Iteration 8, LR1 with threshold 0.4: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 8, LR1 with threshold 0.6: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 8, LR1 with threshold 0.7: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 9, LR1 with threshold 0.5: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 9, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.913, Recall = 0.980\n",
            "Iteration 9, LR1 with threshold 0.4: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 9, LR1 with threshold 0.6: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 9, LR1 with threshold 0.7: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 10, LR1 with threshold 0.5: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 10, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.913, Recall = 0.980\n",
            "Iteration 10, LR1 with threshold 0.4: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 10, LR1 with threshold 0.6: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 10, LR1 with threshold 0.7: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.93072824 0.92895204 0.93072824 0.93250444 0.93250444]\n",
            "Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.91511936 0.91269841 0.91511936 0.91755319 0.91755319]\n",
            "Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.98011364 0.98011364 0.98011364 0.98011364 0.98011364]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = np.zeros((10, 5))\n",
        "precisions = np.zeros((10, 5))\n",
        "recalls = np.zeros((10, 5))\n",
        "\n",
        "for i in range(10):\n",
        "    lr1 = LogisticRegression(alpha=0.0001)\n",
        "    theta1, cost_history1 = lr1.batch_gradient_descent(X.astype(float), y.astype(float))\n",
        "    thresholds = [0.5, 0.3, 0.4, 0.6, 0.7]\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = lr1.predict(X, theta1, threshold=threshold)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        precision = np.sum((y_pred == 1) & (y == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y == 1)) / np.sum(y == 1)\n",
        "        accuracies[i, j] = accuracy\n",
        "        precisions[i, j] = precision\n",
        "        recalls[i, j] = recall\n",
        "        print(f\"Iteration {i+1}, LR1 with threshold {threshold}: Accuracy = {accuracy:.3f}, Precision = {precision:.3f}, Recall = {recall:.3f}\")\n",
        "    \n",
        "print(f\"Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(accuracies, axis=0)}\")\n",
        "print(f\"Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(precisions, axis=0)}\")\n",
        "print(f\"Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(recalls, axis=0)}\")"
      ],
      "metadata": {
        "id": "RMn-7DVw_UdW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26e723db-f534-4bcc-85b5-a5111aa08120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-7bdc6e4aa47a>:13: RuntimeWarning: divide by zero encountered in log\n",
            "  J = (-1/m) * (y.T.dot(np.log(h)) + (1-y).T.dot(np.log(1-h)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, LR1 with threshold 0.5: Accuracy = 0.922, Precision = 0.935, Recall = 0.940\n",
            "Iteration 1, LR1 with threshold 0.3: Accuracy = 0.925, Precision = 0.926, Recall = 0.957\n",
            "Iteration 1, LR1 with threshold 0.4: Accuracy = 0.922, Precision = 0.930, Recall = 0.946\n",
            "Iteration 1, LR1 with threshold 0.6: Accuracy = 0.922, Precision = 0.938, Recall = 0.938\n",
            "Iteration 1, LR1 with threshold 0.7: Accuracy = 0.917, Precision = 0.945, Recall = 0.920\n",
            "Iteration 2, LR1 with threshold 0.5: Accuracy = 0.922, Precision = 0.935, Recall = 0.940\n",
            "Iteration 2, LR1 with threshold 0.3: Accuracy = 0.925, Precision = 0.926, Recall = 0.957\n",
            "Iteration 2, LR1 with threshold 0.4: Accuracy = 0.922, Precision = 0.930, Recall = 0.946\n",
            "Iteration 2, LR1 with threshold 0.6: Accuracy = 0.922, Precision = 0.938, Recall = 0.938\n",
            "Iteration 2, LR1 with threshold 0.7: Accuracy = 0.917, Precision = 0.945, Recall = 0.920\n",
            "Iteration 3, LR1 with threshold 0.5: Accuracy = 0.922, Precision = 0.935, Recall = 0.940\n",
            "Iteration 3, LR1 with threshold 0.3: Accuracy = 0.925, Precision = 0.926, Recall = 0.957\n",
            "Iteration 3, LR1 with threshold 0.4: Accuracy = 0.922, Precision = 0.930, Recall = 0.946\n",
            "Iteration 3, LR1 with threshold 0.6: Accuracy = 0.922, Precision = 0.938, Recall = 0.938\n",
            "Iteration 3, LR1 with threshold 0.7: Accuracy = 0.917, Precision = 0.945, Recall = 0.920\n",
            "Iteration 4, LR1 with threshold 0.5: Accuracy = 0.922, Precision = 0.935, Recall = 0.940\n",
            "Iteration 4, LR1 with threshold 0.3: Accuracy = 0.925, Precision = 0.926, Recall = 0.957\n",
            "Iteration 4, LR1 with threshold 0.4: Accuracy = 0.922, Precision = 0.930, Recall = 0.946\n",
            "Iteration 4, LR1 with threshold 0.6: Accuracy = 0.922, Precision = 0.938, Recall = 0.938\n",
            "Iteration 4, LR1 with threshold 0.7: Accuracy = 0.917, Precision = 0.945, Recall = 0.920\n",
            "Iteration 5, LR1 with threshold 0.5: Accuracy = 0.922, Precision = 0.935, Recall = 0.940\n",
            "Iteration 5, LR1 with threshold 0.3: Accuracy = 0.925, Precision = 0.926, Recall = 0.957\n",
            "Iteration 5, LR1 with threshold 0.4: Accuracy = 0.922, Precision = 0.930, Recall = 0.946\n",
            "Iteration 5, LR1 with threshold 0.6: Accuracy = 0.922, Precision = 0.938, Recall = 0.938\n",
            "Iteration 5, LR1 with threshold 0.7: Accuracy = 0.917, Precision = 0.945, Recall = 0.920\n",
            "Iteration 6, LR1 with threshold 0.5: Accuracy = 0.922, Precision = 0.935, Recall = 0.940\n",
            "Iteration 6, LR1 with threshold 0.3: Accuracy = 0.925, Precision = 0.926, Recall = 0.957\n",
            "Iteration 6, LR1 with threshold 0.4: Accuracy = 0.922, Precision = 0.930, Recall = 0.946\n",
            "Iteration 6, LR1 with threshold 0.6: Accuracy = 0.922, Precision = 0.938, Recall = 0.938\n",
            "Iteration 6, LR1 with threshold 0.7: Accuracy = 0.917, Precision = 0.945, Recall = 0.920\n",
            "Iteration 7, LR1 with threshold 0.5: Accuracy = 0.922, Precision = 0.935, Recall = 0.940\n",
            "Iteration 7, LR1 with threshold 0.3: Accuracy = 0.925, Precision = 0.926, Recall = 0.957\n",
            "Iteration 7, LR1 with threshold 0.4: Accuracy = 0.922, Precision = 0.930, Recall = 0.946\n",
            "Iteration 7, LR1 with threshold 0.6: Accuracy = 0.922, Precision = 0.938, Recall = 0.938\n",
            "Iteration 7, LR1 with threshold 0.7: Accuracy = 0.917, Precision = 0.945, Recall = 0.920\n",
            "Iteration 8, LR1 with threshold 0.5: Accuracy = 0.922, Precision = 0.935, Recall = 0.940\n",
            "Iteration 8, LR1 with threshold 0.3: Accuracy = 0.925, Precision = 0.926, Recall = 0.957\n",
            "Iteration 8, LR1 with threshold 0.4: Accuracy = 0.922, Precision = 0.930, Recall = 0.946\n",
            "Iteration 8, LR1 with threshold 0.6: Accuracy = 0.922, Precision = 0.938, Recall = 0.938\n",
            "Iteration 8, LR1 with threshold 0.7: Accuracy = 0.917, Precision = 0.945, Recall = 0.920\n",
            "Iteration 9, LR1 with threshold 0.5: Accuracy = 0.922, Precision = 0.935, Recall = 0.940\n",
            "Iteration 9, LR1 with threshold 0.3: Accuracy = 0.925, Precision = 0.926, Recall = 0.957\n",
            "Iteration 9, LR1 with threshold 0.4: Accuracy = 0.922, Precision = 0.930, Recall = 0.946\n",
            "Iteration 9, LR1 with threshold 0.6: Accuracy = 0.922, Precision = 0.938, Recall = 0.938\n",
            "Iteration 9, LR1 with threshold 0.7: Accuracy = 0.917, Precision = 0.945, Recall = 0.920\n",
            "Iteration 10, LR1 with threshold 0.5: Accuracy = 0.922, Precision = 0.935, Recall = 0.940\n",
            "Iteration 10, LR1 with threshold 0.3: Accuracy = 0.925, Precision = 0.926, Recall = 0.957\n",
            "Iteration 10, LR1 with threshold 0.4: Accuracy = 0.922, Precision = 0.930, Recall = 0.946\n",
            "Iteration 10, LR1 with threshold 0.6: Accuracy = 0.922, Precision = 0.938, Recall = 0.938\n",
            "Iteration 10, LR1 with threshold 0.7: Accuracy = 0.917, Precision = 0.945, Recall = 0.920\n",
            "Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.92184725 0.92539964 0.92184725 0.92184725 0.91651865]\n",
            "Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.93502825 0.92582418 0.9301676  0.9375     0.94460641]\n",
            "Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.94034091 0.95738636 0.94602273 0.9375     0.92045455]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Mini Batch Gradient Descent With Different Learning Rates (Alpha)"
      ],
      "metadata": {
        "id": "uNRB2985Rc0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = np.zeros((10, 5))\n",
        "precisions = np.zeros((10, 5))\n",
        "recalls = np.zeros((10, 5))\n",
        "\n",
        "for i in range(10):\n",
        "    lr1 = LogisticRegression(alpha=0.01)\n",
        "    theta1, cost_history1 = lr1.mini_batch_gradient_descent(X.astype(float), y.astype(float))\n",
        "    thresholds = [0.5, 0.3, 0.4, 0.6, 0.7]\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = lr1.predict(X, theta1, threshold=threshold)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        precision = np.sum((y_pred == 1) & (y == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y == 1)) / np.sum(y == 1)\n",
        "        accuracies[i, j] = accuracy\n",
        "        precisions[i, j] = precision\n",
        "        recalls[i, j] = recall\n",
        "        print(f\"Iteration {i+1}, LR1 with threshold {threshold}: Accuracy = {accuracy:.3f}, Precision = {precision:.3f}, Recall = {recall:.3f}\")\n",
        "\n",
        "print(f\"Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(accuracies, axis=0)}\")\n",
        "print(f\"Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(precisions, axis=0)}\")\n",
        "print(f\"Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(recalls, axis=0)}\")"
      ],
      "metadata": {
        "id": "wldIYt6RRmqZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34d9890d-4128-45e3-8816-55a000c16b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-7bdc6e4aa47a>:8: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n",
            "<ipython-input-5-7bdc6e4aa47a>:13: RuntimeWarning: divide by zero encountered in log\n",
            "  J = (-1/m) * (y.T.dot(np.log(h)) + (1-y).T.dot(np.log(1-h)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, LR1 with threshold 0.5: Accuracy = 0.924, Precision = 0.933, Recall = 0.946\n",
            "Iteration 1, LR1 with threshold 0.3: Accuracy = 0.924, Precision = 0.933, Recall = 0.946\n",
            "Iteration 1, LR1 with threshold 0.4: Accuracy = 0.924, Precision = 0.933, Recall = 0.946\n",
            "Iteration 1, LR1 with threshold 0.6: Accuracy = 0.924, Precision = 0.933, Recall = 0.946\n",
            "Iteration 1, LR1 with threshold 0.7: Accuracy = 0.924, Precision = 0.933, Recall = 0.946\n",
            "Iteration 2, LR1 with threshold 0.5: Accuracy = 0.906, Precision = 0.873, Recall = 0.994\n",
            "Iteration 2, LR1 with threshold 0.3: Accuracy = 0.906, Precision = 0.873, Recall = 0.994\n",
            "Iteration 2, LR1 with threshold 0.4: Accuracy = 0.906, Precision = 0.873, Recall = 0.994\n",
            "Iteration 2, LR1 with threshold 0.6: Accuracy = 0.906, Precision = 0.873, Recall = 0.994\n",
            "Iteration 2, LR1 with threshold 0.7: Accuracy = 0.906, Precision = 0.873, Recall = 0.994\n",
            "Iteration 3, LR1 with threshold 0.5: Accuracy = 0.911, Precision = 0.952, Recall = 0.903\n",
            "Iteration 3, LR1 with threshold 0.3: Accuracy = 0.911, Precision = 0.952, Recall = 0.903\n",
            "Iteration 3, LR1 with threshold 0.4: Accuracy = 0.911, Precision = 0.952, Recall = 0.903\n",
            "Iteration 3, LR1 with threshold 0.6: Accuracy = 0.911, Precision = 0.952, Recall = 0.903\n",
            "Iteration 3, LR1 with threshold 0.7: Accuracy = 0.911, Precision = 0.952, Recall = 0.903\n",
            "Iteration 4, LR1 with threshold 0.5: Accuracy = 0.929, Precision = 0.908, Recall = 0.986\n",
            "Iteration 4, LR1 with threshold 0.3: Accuracy = 0.929, Precision = 0.908, Recall = 0.986\n",
            "Iteration 4, LR1 with threshold 0.4: Accuracy = 0.929, Precision = 0.908, Recall = 0.986\n",
            "Iteration 4, LR1 with threshold 0.6: Accuracy = 0.929, Precision = 0.908, Recall = 0.986\n",
            "Iteration 4, LR1 with threshold 0.7: Accuracy = 0.929, Precision = 0.908, Recall = 0.986\n",
            "Iteration 5, LR1 with threshold 0.5: Accuracy = 0.922, Precision = 0.935, Recall = 0.940\n",
            "Iteration 5, LR1 with threshold 0.3: Accuracy = 0.922, Precision = 0.935, Recall = 0.940\n",
            "Iteration 5, LR1 with threshold 0.4: Accuracy = 0.922, Precision = 0.935, Recall = 0.940\n",
            "Iteration 5, LR1 with threshold 0.6: Accuracy = 0.922, Precision = 0.935, Recall = 0.940\n",
            "Iteration 5, LR1 with threshold 0.7: Accuracy = 0.922, Precision = 0.935, Recall = 0.940\n",
            "Iteration 6, LR1 with threshold 0.5: Accuracy = 0.918, Precision = 0.935, Recall = 0.935\n",
            "Iteration 6, LR1 with threshold 0.3: Accuracy = 0.918, Precision = 0.935, Recall = 0.935\n",
            "Iteration 6, LR1 with threshold 0.4: Accuracy = 0.918, Precision = 0.935, Recall = 0.935\n",
            "Iteration 6, LR1 with threshold 0.6: Accuracy = 0.918, Precision = 0.935, Recall = 0.935\n",
            "Iteration 6, LR1 with threshold 0.7: Accuracy = 0.918, Precision = 0.935, Recall = 0.935\n",
            "Iteration 7, LR1 with threshold 0.5: Accuracy = 0.837, Precision = 0.974, Recall = 0.759\n",
            "Iteration 7, LR1 with threshold 0.3: Accuracy = 0.837, Precision = 0.974, Recall = 0.759\n",
            "Iteration 7, LR1 with threshold 0.4: Accuracy = 0.837, Precision = 0.974, Recall = 0.759\n",
            "Iteration 7, LR1 with threshold 0.6: Accuracy = 0.837, Precision = 0.974, Recall = 0.759\n",
            "Iteration 7, LR1 with threshold 0.7: Accuracy = 0.837, Precision = 0.974, Recall = 0.759\n",
            "Iteration 8, LR1 with threshold 0.5: Accuracy = 0.931, Precision = 0.911, Recall = 0.986\n",
            "Iteration 8, LR1 with threshold 0.3: Accuracy = 0.931, Precision = 0.911, Recall = 0.986\n",
            "Iteration 8, LR1 with threshold 0.4: Accuracy = 0.931, Precision = 0.911, Recall = 0.986\n",
            "Iteration 8, LR1 with threshold 0.6: Accuracy = 0.931, Precision = 0.911, Recall = 0.986\n",
            "Iteration 8, LR1 with threshold 0.7: Accuracy = 0.931, Precision = 0.911, Recall = 0.986\n",
            "Iteration 9, LR1 with threshold 0.5: Accuracy = 0.922, Precision = 0.925, Recall = 0.952\n",
            "Iteration 9, LR1 with threshold 0.3: Accuracy = 0.922, Precision = 0.925, Recall = 0.952\n",
            "Iteration 9, LR1 with threshold 0.4: Accuracy = 0.922, Precision = 0.925, Recall = 0.952\n",
            "Iteration 9, LR1 with threshold 0.6: Accuracy = 0.922, Precision = 0.925, Recall = 0.952\n",
            "Iteration 9, LR1 with threshold 0.7: Accuracy = 0.924, Precision = 0.928, Recall = 0.952\n",
            "Iteration 10, LR1 with threshold 0.5: Accuracy = 0.934, Precision = 0.916, Recall = 0.986\n",
            "Iteration 10, LR1 with threshold 0.3: Accuracy = 0.934, Precision = 0.916, Recall = 0.986\n",
            "Iteration 10, LR1 with threshold 0.4: Accuracy = 0.934, Precision = 0.916, Recall = 0.986\n",
            "Iteration 10, LR1 with threshold 0.6: Accuracy = 0.934, Precision = 0.916, Recall = 0.986\n",
            "Iteration 10, LR1 with threshold 0.7: Accuracy = 0.934, Precision = 0.916, Recall = 0.986\n",
            "Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.91332149 0.91332149 0.91332149 0.91332149 0.91349911]\n",
            "Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.92619465 0.92619465 0.92619465 0.92619465 0.926451  ]\n",
            "Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.93863636 0.93863636 0.93863636 0.93863636 0.93863636]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = np.zeros((10, 5))\n",
        "precisions = np.zeros((10, 5))\n",
        "recalls = np.zeros((10, 5))\n",
        "\n",
        "for i in range(10):\n",
        "    lr1 = LogisticRegression(alpha=0.001)\n",
        "    theta1, cost_history1 = lr1.mini_batch_gradient_descent(X.astype(float), y.astype(float))\n",
        "    thresholds = [0.5, 0.3, 0.4, 0.6, 0.7]\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = lr1.predict(X, theta1, threshold=threshold)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        precision = np.sum((y_pred == 1) & (y == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y == 1)) / np.sum(y == 1)\n",
        "        accuracies[i, j] = accuracy\n",
        "        precisions[i, j] = precision\n",
        "        recalls[i, j] = recall\n",
        "        print(f\"Iteration {i+1}, LR1 with threshold {threshold}: Accuracy = {accuracy:.3f}, Precision = {precision:.3f}, Recall = {recall:.3f}\")\n",
        "\n",
        "print(f\"Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(accuracies, axis=0)}\")\n",
        "print(f\"Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(precisions, axis=0)}\")\n",
        "print(f\"Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(recalls, axis=0)}\")"
      ],
      "metadata": {
        "id": "KBe2z-BPRp7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f6c0b2-0fc1-4d5f-81a5-ffa2e90a42c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-7bdc6e4aa47a>:13: RuntimeWarning: divide by zero encountered in log\n",
            "  J = (-1/m) * (y.T.dot(np.log(h)) + (1-y).T.dot(np.log(1-h)))\n",
            "<ipython-input-5-7bdc6e4aa47a>:8: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, LR1 with threshold 0.5: Accuracy = 0.913, Precision = 0.950, Recall = 0.909\n",
            "Iteration 1, LR1 with threshold 0.3: Accuracy = 0.915, Precision = 0.950, Recall = 0.912\n",
            "Iteration 1, LR1 with threshold 0.4: Accuracy = 0.915, Precision = 0.950, Recall = 0.912\n",
            "Iteration 1, LR1 with threshold 0.6: Accuracy = 0.913, Precision = 0.950, Recall = 0.909\n",
            "Iteration 1, LR1 with threshold 0.7: Accuracy = 0.913, Precision = 0.950, Recall = 0.909\n",
            "Iteration 2, LR1 with threshold 0.5: Accuracy = 0.920, Precision = 0.932, Recall = 0.940\n",
            "Iteration 2, LR1 with threshold 0.3: Accuracy = 0.922, Precision = 0.933, Recall = 0.943\n",
            "Iteration 2, LR1 with threshold 0.4: Accuracy = 0.920, Precision = 0.932, Recall = 0.940\n",
            "Iteration 2, LR1 with threshold 0.6: Accuracy = 0.920, Precision = 0.932, Recall = 0.940\n",
            "Iteration 2, LR1 with threshold 0.7: Accuracy = 0.920, Precision = 0.932, Recall = 0.940\n",
            "Iteration 3, LR1 with threshold 0.5: Accuracy = 0.876, Precision = 0.973, Recall = 0.824\n",
            "Iteration 3, LR1 with threshold 0.3: Accuracy = 0.876, Precision = 0.973, Recall = 0.824\n",
            "Iteration 3, LR1 with threshold 0.4: Accuracy = 0.876, Precision = 0.973, Recall = 0.824\n",
            "Iteration 3, LR1 with threshold 0.6: Accuracy = 0.876, Precision = 0.973, Recall = 0.824\n",
            "Iteration 3, LR1 with threshold 0.7: Accuracy = 0.874, Precision = 0.973, Recall = 0.821\n",
            "Iteration 4, LR1 with threshold 0.5: Accuracy = 0.925, Precision = 0.917, Recall = 0.969\n",
            "Iteration 4, LR1 with threshold 0.3: Accuracy = 0.927, Precision = 0.917, Recall = 0.972\n",
            "Iteration 4, LR1 with threshold 0.4: Accuracy = 0.925, Precision = 0.917, Recall = 0.969\n",
            "Iteration 4, LR1 with threshold 0.6: Accuracy = 0.925, Precision = 0.917, Recall = 0.969\n",
            "Iteration 4, LR1 with threshold 0.7: Accuracy = 0.925, Precision = 0.917, Recall = 0.969\n",
            "Iteration 5, LR1 with threshold 0.5: Accuracy = 0.933, Precision = 0.913, Recall = 0.986\n",
            "Iteration 5, LR1 with threshold 0.3: Accuracy = 0.931, Precision = 0.911, Recall = 0.986\n",
            "Iteration 5, LR1 with threshold 0.4: Accuracy = 0.933, Precision = 0.913, Recall = 0.986\n",
            "Iteration 5, LR1 with threshold 0.6: Accuracy = 0.933, Precision = 0.913, Recall = 0.986\n",
            "Iteration 5, LR1 with threshold 0.7: Accuracy = 0.933, Precision = 0.913, Recall = 0.986\n",
            "Iteration 6, LR1 with threshold 0.5: Accuracy = 0.833, Precision = 0.985, Recall = 0.744\n",
            "Iteration 6, LR1 with threshold 0.3: Accuracy = 0.835, Precision = 0.985, Recall = 0.747\n",
            "Iteration 6, LR1 with threshold 0.4: Accuracy = 0.835, Precision = 0.985, Recall = 0.747\n",
            "Iteration 6, LR1 with threshold 0.6: Accuracy = 0.828, Precision = 0.985, Recall = 0.736\n",
            "Iteration 6, LR1 with threshold 0.7: Accuracy = 0.826, Precision = 0.985, Recall = 0.733\n",
            "Iteration 7, LR1 with threshold 0.5: Accuracy = 0.924, Precision = 0.899, Recall = 0.989\n",
            "Iteration 7, LR1 with threshold 0.3: Accuracy = 0.924, Precision = 0.899, Recall = 0.989\n",
            "Iteration 7, LR1 with threshold 0.4: Accuracy = 0.924, Precision = 0.899, Recall = 0.989\n",
            "Iteration 7, LR1 with threshold 0.6: Accuracy = 0.924, Precision = 0.899, Recall = 0.989\n",
            "Iteration 7, LR1 with threshold 0.7: Accuracy = 0.924, Precision = 0.899, Recall = 0.989\n",
            "Iteration 8, LR1 with threshold 0.5: Accuracy = 0.895, Precision = 0.965, Recall = 0.864\n",
            "Iteration 8, LR1 with threshold 0.3: Accuracy = 0.897, Precision = 0.965, Recall = 0.866\n",
            "Iteration 8, LR1 with threshold 0.4: Accuracy = 0.895, Precision = 0.965, Recall = 0.864\n",
            "Iteration 8, LR1 with threshold 0.6: Accuracy = 0.893, Precision = 0.965, Recall = 0.861\n",
            "Iteration 8, LR1 with threshold 0.7: Accuracy = 0.893, Precision = 0.968, Recall = 0.858\n",
            "Iteration 9, LR1 with threshold 0.5: Accuracy = 0.876, Precision = 0.973, Recall = 0.824\n",
            "Iteration 9, LR1 with threshold 0.3: Accuracy = 0.876, Precision = 0.973, Recall = 0.824\n",
            "Iteration 9, LR1 with threshold 0.4: Accuracy = 0.876, Precision = 0.973, Recall = 0.824\n",
            "Iteration 9, LR1 with threshold 0.6: Accuracy = 0.876, Precision = 0.973, Recall = 0.824\n",
            "Iteration 9, LR1 with threshold 0.7: Accuracy = 0.876, Precision = 0.973, Recall = 0.824\n",
            "Iteration 10, LR1 with threshold 0.5: Accuracy = 0.897, Precision = 0.962, Recall = 0.869\n",
            "Iteration 10, LR1 with threshold 0.3: Accuracy = 0.897, Precision = 0.962, Recall = 0.869\n",
            "Iteration 10, LR1 with threshold 0.4: Accuracy = 0.897, Precision = 0.962, Recall = 0.869\n",
            "Iteration 10, LR1 with threshold 0.6: Accuracy = 0.897, Precision = 0.962, Recall = 0.869\n",
            "Iteration 10, LR1 with threshold 0.7: Accuracy = 0.899, Precision = 0.965, Recall = 0.869\n",
            "Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.8991119  0.89982238 0.89946714 0.89840142 0.8982238 ]\n",
            "Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.94696133 0.94679459 0.94698188 0.94693305 0.94751982]\n",
            "Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.89176136 0.89318182 0.89232955 0.890625   0.88977273]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = np.zeros((10, 5))\n",
        "precisions = np.zeros((10, 5))\n",
        "recalls = np.zeros((10, 5))\n",
        "\n",
        "for i in range(10):\n",
        "    lr1 = LogisticRegression(alpha=0.0001)\n",
        "    theta1, cost_history1 = lr1.mini_batch_gradient_descent(X.astype(float), y.astype(float))\n",
        "    thresholds = [0.5, 0.3, 0.4, 0.6, 0.7]\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = lr1.predict(X, theta1, threshold=threshold)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        precision = np.sum((y_pred == 1) & (y == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y == 1)) / np.sum(y == 1)\n",
        "        accuracies[i, j] = accuracy\n",
        "        precisions[i, j] = precision\n",
        "        recalls[i, j] = recall\n",
        "        print(f\"Iteration {i+1}, LR1 with threshold {threshold}: Accuracy = {accuracy:.3f}, Precision = {precision:.3f}, Recall = {recall:.3f}\")\n",
        "\n",
        "print(f\"Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(accuracies, axis=0)}\")\n",
        "print(f\"Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(precisions, axis=0)}\")\n",
        "print(f\"Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(recalls, axis=0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNsncApZh_T_",
        "outputId": "67f835c4-ecdf-4187-bc4a-8599ea9862f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-7bdc6e4aa47a>:13: RuntimeWarning: divide by zero encountered in log\n",
            "  J = (-1/m) * (y.T.dot(np.log(h)) + (1-y).T.dot(np.log(1-h)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, LR1 with threshold 0.5: Accuracy = 0.908, Precision = 0.875, Recall = 0.994\n",
            "Iteration 1, LR1 with threshold 0.3: Accuracy = 0.904, Precision = 0.871, Recall = 0.994\n",
            "Iteration 1, LR1 with threshold 0.4: Accuracy = 0.904, Precision = 0.871, Recall = 0.994\n",
            "Iteration 1, LR1 with threshold 0.6: Accuracy = 0.913, Precision = 0.882, Recall = 0.994\n",
            "Iteration 1, LR1 with threshold 0.7: Accuracy = 0.917, Precision = 0.886, Recall = 0.994\n",
            "Iteration 2, LR1 with threshold 0.5: Accuracy = 0.920, Precision = 0.932, Recall = 0.940\n",
            "Iteration 2, LR1 with threshold 0.3: Accuracy = 0.924, Precision = 0.923, Recall = 0.957\n",
            "Iteration 2, LR1 with threshold 0.4: Accuracy = 0.925, Precision = 0.933, Recall = 0.949\n",
            "Iteration 2, LR1 with threshold 0.6: Accuracy = 0.920, Precision = 0.937, Recall = 0.935\n",
            "Iteration 2, LR1 with threshold 0.7: Accuracy = 0.917, Precision = 0.939, Recall = 0.926\n",
            "Iteration 3, LR1 with threshold 0.5: Accuracy = 0.933, Precision = 0.913, Recall = 0.986\n",
            "Iteration 3, LR1 with threshold 0.3: Accuracy = 0.927, Precision = 0.906, Recall = 0.986\n",
            "Iteration 3, LR1 with threshold 0.4: Accuracy = 0.929, Precision = 0.908, Recall = 0.986\n",
            "Iteration 3, LR1 with threshold 0.6: Accuracy = 0.934, Precision = 0.916, Recall = 0.986\n",
            "Iteration 3, LR1 with threshold 0.7: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 4, LR1 with threshold 0.5: Accuracy = 0.920, Precision = 0.935, Recall = 0.938\n",
            "Iteration 4, LR1 with threshold 0.3: Accuracy = 0.920, Precision = 0.923, Recall = 0.952\n",
            "Iteration 4, LR1 with threshold 0.4: Accuracy = 0.922, Precision = 0.935, Recall = 0.940\n",
            "Iteration 4, LR1 with threshold 0.6: Accuracy = 0.922, Precision = 0.943, Recall = 0.932\n",
            "Iteration 4, LR1 with threshold 0.7: Accuracy = 0.920, Precision = 0.945, Recall = 0.926\n",
            "Iteration 5, LR1 with threshold 0.5: Accuracy = 0.917, Precision = 0.890, Recall = 0.989\n",
            "Iteration 5, LR1 with threshold 0.3: Accuracy = 0.917, Precision = 0.886, Recall = 0.994\n",
            "Iteration 5, LR1 with threshold 0.4: Accuracy = 0.917, Precision = 0.888, Recall = 0.991\n",
            "Iteration 5, LR1 with threshold 0.6: Accuracy = 0.917, Precision = 0.890, Recall = 0.989\n",
            "Iteration 5, LR1 with threshold 0.7: Accuracy = 0.924, Precision = 0.899, Recall = 0.989\n",
            "Iteration 6, LR1 with threshold 0.5: Accuracy = 0.934, Precision = 0.916, Recall = 0.986\n",
            "Iteration 6, LR1 with threshold 0.3: Accuracy = 0.927, Precision = 0.906, Recall = 0.986\n",
            "Iteration 6, LR1 with threshold 0.4: Accuracy = 0.931, Precision = 0.911, Recall = 0.986\n",
            "Iteration 6, LR1 with threshold 0.6: Accuracy = 0.933, Precision = 0.918, Recall = 0.980\n",
            "Iteration 6, LR1 with threshold 0.7: Accuracy = 0.927, Precision = 0.917, Recall = 0.972\n",
            "Iteration 7, LR1 with threshold 0.5: Accuracy = 0.879, Precision = 0.973, Recall = 0.830\n",
            "Iteration 7, LR1 with threshold 0.3: Accuracy = 0.897, Precision = 0.971, Recall = 0.861\n",
            "Iteration 7, LR1 with threshold 0.4: Accuracy = 0.890, Precision = 0.974, Recall = 0.847\n",
            "Iteration 7, LR1 with threshold 0.6: Accuracy = 0.872, Precision = 0.973, Recall = 0.818\n",
            "Iteration 7, LR1 with threshold 0.7: Accuracy = 0.867, Precision = 0.973, Recall = 0.810\n",
            "Iteration 8, LR1 with threshold 0.5: Accuracy = 0.913, Precision = 0.950, Recall = 0.909\n",
            "Iteration 8, LR1 with threshold 0.3: Accuracy = 0.917, Precision = 0.947, Recall = 0.918\n",
            "Iteration 8, LR1 with threshold 0.4: Accuracy = 0.915, Precision = 0.950, Recall = 0.912\n",
            "Iteration 8, LR1 with threshold 0.6: Accuracy = 0.909, Precision = 0.952, Recall = 0.901\n",
            "Iteration 8, LR1 with threshold 0.7: Accuracy = 0.904, Precision = 0.954, Recall = 0.889\n",
            "Iteration 9, LR1 with threshold 0.5: Accuracy = 0.929, Precision = 0.908, Recall = 0.986\n",
            "Iteration 9, LR1 with threshold 0.3: Accuracy = 0.927, Precision = 0.904, Recall = 0.989\n",
            "Iteration 9, LR1 with threshold 0.4: Accuracy = 0.927, Precision = 0.906, Recall = 0.986\n",
            "Iteration 9, LR1 with threshold 0.6: Accuracy = 0.933, Precision = 0.913, Recall = 0.986\n",
            "Iteration 9, LR1 with threshold 0.7: Accuracy = 0.933, Precision = 0.915, Recall = 0.983\n",
            "Iteration 10, LR1 with threshold 0.5: Accuracy = 0.920, Precision = 0.942, Recall = 0.929\n",
            "Iteration 10, LR1 with threshold 0.3: Accuracy = 0.920, Precision = 0.935, Recall = 0.938\n",
            "Iteration 10, LR1 with threshold 0.4: Accuracy = 0.922, Precision = 0.940, Recall = 0.935\n",
            "Iteration 10, LR1 with threshold 0.6: Accuracy = 0.918, Precision = 0.947, Recall = 0.920\n",
            "Iteration 10, LR1 with threshold 0.7: Accuracy = 0.913, Precision = 0.950, Recall = 0.909\n",
            "Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.91722913 0.91793961 0.91811723 0.91705151 0.91527531]\n",
            "Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.92346176 0.91719941 0.92153803 0.92700601 0.92960162]\n",
            "Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.94857955 0.95738636 0.95255682 0.94403409 0.93778409]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stochaistic Gradient Descent With Different Learning Rates (Alpha)"
      ],
      "metadata": {
        "id": "z2Adoo9SiD5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = np.zeros((10, 5))\n",
        "precisions = np.zeros((10, 5))\n",
        "recalls = np.zeros((10, 5))\n",
        "\n",
        "for i in range(10):\n",
        "    lr1 = LogisticRegression(alpha=0.01)\n",
        "    theta1, cost_history1 = lr1.stochastic_gradient_descent(X.astype(float), y.astype(float))\n",
        "    thresholds = [0.5, 0.3, 0.4, 0.6, 0.7]\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = lr1.predict(X, theta1, threshold=threshold)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        precision = np.sum((y_pred == 1) & (y == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y == 1)) / np.sum(y == 1)\n",
        "        accuracies[i, j] = accuracy\n",
        "        precisions[i, j] = precision\n",
        "        recalls[i, j] = recall\n",
        "        print(f\"Iteration {i+1}, LR1 with threshold {threshold}: Accuracy = {accuracy:.3f}, Precision = {precision:.3f}, Recall = {recall:.3f}\")\n",
        "\n",
        "print(f\"Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(accuracies, axis=0)}\")\n",
        "print(f\"Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(precisions, axis=0)}\")\n",
        "print(f\"Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(recalls, axis=0)}\")"
      ],
      "metadata": {
        "id": "ERWUjgbERtpB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dd96062-6682-46cb-cbc3-4027f44f33db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-7bdc6e4aa47a>:8: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n",
            "<ipython-input-5-7bdc6e4aa47a>:13: RuntimeWarning: divide by zero encountered in log\n",
            "  J = (-1/m) * (y.T.dot(np.log(h)) + (1-y).T.dot(np.log(1-h)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, LR1 with threshold 0.5: Accuracy = 0.941, Precision = 0.947, Recall = 0.960\n",
            "Iteration 1, LR1 with threshold 0.3: Accuracy = 0.941, Precision = 0.947, Recall = 0.960\n",
            "Iteration 1, LR1 with threshold 0.4: Accuracy = 0.941, Precision = 0.947, Recall = 0.960\n",
            "Iteration 1, LR1 with threshold 0.6: Accuracy = 0.941, Precision = 0.947, Recall = 0.960\n",
            "Iteration 1, LR1 with threshold 0.7: Accuracy = 0.941, Precision = 0.947, Recall = 0.960\n",
            "Iteration 2, LR1 with threshold 0.5: Accuracy = 0.938, Precision = 0.957, Recall = 0.943\n",
            "Iteration 2, LR1 with threshold 0.3: Accuracy = 0.938, Precision = 0.957, Recall = 0.943\n",
            "Iteration 2, LR1 with threshold 0.4: Accuracy = 0.938, Precision = 0.957, Recall = 0.943\n",
            "Iteration 2, LR1 with threshold 0.6: Accuracy = 0.938, Precision = 0.957, Recall = 0.943\n",
            "Iteration 2, LR1 with threshold 0.7: Accuracy = 0.938, Precision = 0.957, Recall = 0.943\n",
            "Iteration 3, LR1 with threshold 0.5: Accuracy = 0.940, Precision = 0.957, Recall = 0.946\n",
            "Iteration 3, LR1 with threshold 0.3: Accuracy = 0.940, Precision = 0.957, Recall = 0.946\n",
            "Iteration 3, LR1 with threshold 0.4: Accuracy = 0.940, Precision = 0.957, Recall = 0.946\n",
            "Iteration 3, LR1 with threshold 0.6: Accuracy = 0.940, Precision = 0.957, Recall = 0.946\n",
            "Iteration 3, LR1 with threshold 0.7: Accuracy = 0.940, Precision = 0.957, Recall = 0.946\n",
            "Iteration 4, LR1 with threshold 0.5: Accuracy = 0.933, Precision = 0.920, Recall = 0.977\n",
            "Iteration 4, LR1 with threshold 0.3: Accuracy = 0.933, Precision = 0.920, Recall = 0.977\n",
            "Iteration 4, LR1 with threshold 0.4: Accuracy = 0.933, Precision = 0.920, Recall = 0.977\n",
            "Iteration 4, LR1 with threshold 0.6: Accuracy = 0.933, Precision = 0.920, Recall = 0.977\n",
            "Iteration 4, LR1 with threshold 0.7: Accuracy = 0.933, Precision = 0.920, Recall = 0.977\n",
            "Iteration 5, LR1 with threshold 0.5: Accuracy = 0.940, Precision = 0.942, Recall = 0.963\n",
            "Iteration 5, LR1 with threshold 0.3: Accuracy = 0.940, Precision = 0.942, Recall = 0.963\n",
            "Iteration 5, LR1 with threshold 0.4: Accuracy = 0.940, Precision = 0.942, Recall = 0.963\n",
            "Iteration 5, LR1 with threshold 0.6: Accuracy = 0.940, Precision = 0.942, Recall = 0.963\n",
            "Iteration 5, LR1 with threshold 0.7: Accuracy = 0.940, Precision = 0.942, Recall = 0.963\n",
            "Iteration 6, LR1 with threshold 0.5: Accuracy = 0.934, Precision = 0.965, Recall = 0.929\n",
            "Iteration 6, LR1 with threshold 0.3: Accuracy = 0.934, Precision = 0.965, Recall = 0.929\n",
            "Iteration 6, LR1 with threshold 0.4: Accuracy = 0.934, Precision = 0.965, Recall = 0.929\n",
            "Iteration 6, LR1 with threshold 0.6: Accuracy = 0.934, Precision = 0.965, Recall = 0.929\n",
            "Iteration 6, LR1 with threshold 0.7: Accuracy = 0.934, Precision = 0.965, Recall = 0.929\n",
            "Iteration 7, LR1 with threshold 0.5: Accuracy = 0.940, Precision = 0.960, Recall = 0.943\n",
            "Iteration 7, LR1 with threshold 0.3: Accuracy = 0.940, Precision = 0.960, Recall = 0.943\n",
            "Iteration 7, LR1 with threshold 0.4: Accuracy = 0.940, Precision = 0.960, Recall = 0.943\n",
            "Iteration 7, LR1 with threshold 0.6: Accuracy = 0.940, Precision = 0.960, Recall = 0.943\n",
            "Iteration 7, LR1 with threshold 0.7: Accuracy = 0.940, Precision = 0.960, Recall = 0.943\n",
            "Iteration 8, LR1 with threshold 0.5: Accuracy = 0.938, Precision = 0.937, Recall = 0.966\n",
            "Iteration 8, LR1 with threshold 0.3: Accuracy = 0.938, Precision = 0.937, Recall = 0.966\n",
            "Iteration 8, LR1 with threshold 0.4: Accuracy = 0.938, Precision = 0.937, Recall = 0.966\n",
            "Iteration 8, LR1 with threshold 0.6: Accuracy = 0.938, Precision = 0.937, Recall = 0.966\n",
            "Iteration 8, LR1 with threshold 0.7: Accuracy = 0.938, Precision = 0.937, Recall = 0.966\n",
            "Iteration 9, LR1 with threshold 0.5: Accuracy = 0.936, Precision = 0.925, Recall = 0.977\n",
            "Iteration 9, LR1 with threshold 0.3: Accuracy = 0.936, Precision = 0.925, Recall = 0.977\n",
            "Iteration 9, LR1 with threshold 0.4: Accuracy = 0.936, Precision = 0.925, Recall = 0.977\n",
            "Iteration 9, LR1 with threshold 0.6: Accuracy = 0.936, Precision = 0.925, Recall = 0.977\n",
            "Iteration 9, LR1 with threshold 0.7: Accuracy = 0.936, Precision = 0.925, Recall = 0.977\n",
            "Iteration 10, LR1 with threshold 0.5: Accuracy = 0.940, Precision = 0.960, Recall = 0.943\n",
            "Iteration 10, LR1 with threshold 0.3: Accuracy = 0.940, Precision = 0.960, Recall = 0.943\n",
            "Iteration 10, LR1 with threshold 0.4: Accuracy = 0.940, Precision = 0.960, Recall = 0.943\n",
            "Iteration 10, LR1 with threshold 0.6: Accuracy = 0.940, Precision = 0.960, Recall = 0.943\n",
            "Iteration 10, LR1 with threshold 0.7: Accuracy = 0.940, Precision = 0.960, Recall = 0.943\n",
            "Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.93783304 0.93783304 0.93783304 0.93783304 0.93783304]\n",
            "Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.94669476 0.94669476 0.94669476 0.94669476 0.94669476]\n",
            "Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.95482955 0.95482955 0.95482955 0.95482955 0.95482955]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = np.zeros((10, 5))\n",
        "precisions = np.zeros((10, 5))\n",
        "recalls = np.zeros((10, 5))\n",
        "\n",
        "for i in range(10):\n",
        "    lr1 = LogisticRegression(alpha=0.001)\n",
        "    theta1, cost_history1 = lr1.stochastic_gradient_descent(X.astype(float), y.astype(float))\n",
        "    thresholds = [0.5, 0.3, 0.4, 0.6, 0.7]\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = lr1.predict(X, theta1, threshold=threshold)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        precision = np.sum((y_pred == 1) & (y == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y == 1)) / np.sum(y == 1)\n",
        "        accuracies[i, j] = accuracy\n",
        "        precisions[i, j] = precision\n",
        "        recalls[i, j] = recall\n",
        "        print(f\"Iteration {i+1}, LR1 with threshold {threshold}: Accuracy = {accuracy:.3f}, Precision = {precision:.3f}, Recall = {recall:.3f}\")\n",
        "\n",
        "print(f\"Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(accuracies, axis=0)}\")\n",
        "print(f\"Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(precisions, axis=0)}\")\n",
        "print(f\"Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(recalls, axis=0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlPxujQAiVB4",
        "outputId": "450f16f6-5b9b-4a44-9095-4c751840635b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-7bdc6e4aa47a>:13: RuntimeWarning: divide by zero encountered in log\n",
            "  J = (-1/m) * (y.T.dot(np.log(h)) + (1-y).T.dot(np.log(1-h)))\n",
            "<ipython-input-5-7bdc6e4aa47a>:8: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, LR1 with threshold 0.5: Accuracy = 0.940, Precision = 0.944, Recall = 0.960\n",
            "Iteration 1, LR1 with threshold 0.3: Accuracy = 0.941, Precision = 0.944, Recall = 0.963\n",
            "Iteration 1, LR1 with threshold 0.4: Accuracy = 0.941, Precision = 0.944, Recall = 0.963\n",
            "Iteration 1, LR1 with threshold 0.6: Accuracy = 0.940, Precision = 0.944, Recall = 0.960\n",
            "Iteration 1, LR1 with threshold 0.7: Accuracy = 0.940, Precision = 0.944, Recall = 0.960\n",
            "Iteration 2, LR1 with threshold 0.5: Accuracy = 0.940, Precision = 0.952, Recall = 0.952\n",
            "Iteration 2, LR1 with threshold 0.3: Accuracy = 0.941, Precision = 0.952, Recall = 0.955\n",
            "Iteration 2, LR1 with threshold 0.4: Accuracy = 0.940, Precision = 0.952, Recall = 0.952\n",
            "Iteration 2, LR1 with threshold 0.6: Accuracy = 0.940, Precision = 0.952, Recall = 0.952\n",
            "Iteration 2, LR1 with threshold 0.7: Accuracy = 0.940, Precision = 0.952, Recall = 0.952\n",
            "Iteration 3, LR1 with threshold 0.5: Accuracy = 0.877, Precision = 0.996, Recall = 0.807\n",
            "Iteration 3, LR1 with threshold 0.3: Accuracy = 0.877, Precision = 0.993, Recall = 0.810\n",
            "Iteration 3, LR1 with threshold 0.4: Accuracy = 0.879, Precision = 0.997, Recall = 0.810\n",
            "Iteration 3, LR1 with threshold 0.6: Accuracy = 0.877, Precision = 0.996, Recall = 0.807\n",
            "Iteration 3, LR1 with threshold 0.7: Accuracy = 0.877, Precision = 0.996, Recall = 0.807\n",
            "Iteration 4, LR1 with threshold 0.5: Accuracy = 0.929, Precision = 0.967, Recall = 0.918\n",
            "Iteration 4, LR1 with threshold 0.3: Accuracy = 0.931, Precision = 0.967, Recall = 0.920\n",
            "Iteration 4, LR1 with threshold 0.4: Accuracy = 0.929, Precision = 0.967, Recall = 0.918\n",
            "Iteration 4, LR1 with threshold 0.6: Accuracy = 0.929, Precision = 0.967, Recall = 0.918\n",
            "Iteration 4, LR1 with threshold 0.7: Accuracy = 0.925, Precision = 0.967, Recall = 0.912\n",
            "Iteration 5, LR1 with threshold 0.5: Accuracy = 0.934, Precision = 0.925, Recall = 0.974\n",
            "Iteration 5, LR1 with threshold 0.3: Accuracy = 0.934, Precision = 0.925, Recall = 0.974\n",
            "Iteration 5, LR1 with threshold 0.4: Accuracy = 0.934, Precision = 0.925, Recall = 0.974\n",
            "Iteration 5, LR1 with threshold 0.6: Accuracy = 0.934, Precision = 0.925, Recall = 0.974\n",
            "Iteration 5, LR1 with threshold 0.7: Accuracy = 0.934, Precision = 0.927, Recall = 0.972\n",
            "Iteration 6, LR1 with threshold 0.5: Accuracy = 0.888, Precision = 0.997, Recall = 0.824\n",
            "Iteration 6, LR1 with threshold 0.3: Accuracy = 0.890, Precision = 0.997, Recall = 0.827\n",
            "Iteration 6, LR1 with threshold 0.4: Accuracy = 0.890, Precision = 0.997, Recall = 0.827\n",
            "Iteration 6, LR1 with threshold 0.6: Accuracy = 0.886, Precision = 0.997, Recall = 0.821\n",
            "Iteration 6, LR1 with threshold 0.7: Accuracy = 0.886, Precision = 0.997, Recall = 0.821\n",
            "Iteration 7, LR1 with threshold 0.5: Accuracy = 0.922, Precision = 0.961, Recall = 0.912\n",
            "Iteration 7, LR1 with threshold 0.3: Accuracy = 0.925, Precision = 0.961, Recall = 0.918\n",
            "Iteration 7, LR1 with threshold 0.4: Accuracy = 0.924, Precision = 0.961, Recall = 0.915\n",
            "Iteration 7, LR1 with threshold 0.6: Accuracy = 0.922, Precision = 0.961, Recall = 0.912\n",
            "Iteration 7, LR1 with threshold 0.7: Accuracy = 0.922, Precision = 0.964, Recall = 0.909\n",
            "Iteration 8, LR1 with threshold 0.5: Accuracy = 0.929, Precision = 0.967, Recall = 0.918\n",
            "Iteration 8, LR1 with threshold 0.3: Accuracy = 0.931, Precision = 0.967, Recall = 0.920\n",
            "Iteration 8, LR1 with threshold 0.4: Accuracy = 0.929, Precision = 0.967, Recall = 0.918\n",
            "Iteration 8, LR1 with threshold 0.6: Accuracy = 0.927, Precision = 0.967, Recall = 0.915\n",
            "Iteration 8, LR1 with threshold 0.7: Accuracy = 0.924, Precision = 0.967, Recall = 0.909\n",
            "Iteration 9, LR1 with threshold 0.5: Accuracy = 0.941, Precision = 0.942, Recall = 0.966\n",
            "Iteration 9, LR1 with threshold 0.3: Accuracy = 0.941, Precision = 0.942, Recall = 0.966\n",
            "Iteration 9, LR1 with threshold 0.4: Accuracy = 0.941, Precision = 0.942, Recall = 0.966\n",
            "Iteration 9, LR1 with threshold 0.6: Accuracy = 0.941, Precision = 0.942, Recall = 0.966\n",
            "Iteration 9, LR1 with threshold 0.7: Accuracy = 0.941, Precision = 0.944, Recall = 0.963\n",
            "Iteration 10, LR1 with threshold 0.5: Accuracy = 0.940, Precision = 0.954, Recall = 0.949\n",
            "Iteration 10, LR1 with threshold 0.3: Accuracy = 0.940, Precision = 0.954, Recall = 0.949\n",
            "Iteration 10, LR1 with threshold 0.4: Accuracy = 0.940, Precision = 0.954, Recall = 0.949\n",
            "Iteration 10, LR1 with threshold 0.6: Accuracy = 0.938, Precision = 0.954, Recall = 0.946\n",
            "Iteration 10, LR1 with threshold 0.7: Accuracy = 0.938, Precision = 0.954, Recall = 0.946\n",
            "Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.92397869 0.92522202 0.92468917 0.92344583 0.92273535]\n",
            "Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.96047453 0.96020179 0.96050411 0.96045035 0.96116455]\n",
            "Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.91789773 0.92017045 0.91903409 0.91704545 0.91505682]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = np.zeros((10, 5))\n",
        "precisions = np.zeros((10, 5))\n",
        "recalls = np.zeros((10, 5))\n",
        "\n",
        "for i in range(10):\n",
        "    lr1 = LogisticRegression(alpha=0.0001)\n",
        "    theta1, cost_history1 = lr1.stochastic_gradient_descent(X.astype(float), y.astype(float))\n",
        "    thresholds = [0.5, 0.3, 0.4, 0.6, 0.7]\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = lr1.predict(X, theta1, threshold=threshold)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        precision = np.sum((y_pred == 1) & (y == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y == 1)) / np.sum(y == 1)\n",
        "        accuracies[i, j] = accuracy\n",
        "        precisions[i, j] = precision\n",
        "        recalls[i, j] = recall\n",
        "        print(f\"Iteration {i+1}, LR1 with threshold {threshold}: Accuracy = {accuracy:.3f}, Precision = {precision:.3f}, Recall = {recall:.3f}\")\n",
        "\n",
        "print(f\"Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(accuracies, axis=0)}\")\n",
        "print(f\"Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(precisions, axis=0)}\")\n",
        "print(f\"Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(recalls, axis=0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mktHDJThiZSs",
        "outputId": "b6e216f2-baea-45de-c6e4-356a78fb7cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-7bdc6e4aa47a>:13: RuntimeWarning: divide by zero encountered in log\n",
            "  J = (-1/m) * (y.T.dot(np.log(h)) + (1-y).T.dot(np.log(1-h)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, LR1 with threshold 0.5: Accuracy = 0.915, Precision = 0.972, Recall = 0.889\n",
            "Iteration 1, LR1 with threshold 0.3: Accuracy = 0.940, Precision = 0.962, Recall = 0.940\n",
            "Iteration 1, LR1 with threshold 0.4: Accuracy = 0.936, Precision = 0.973, Recall = 0.923\n",
            "Iteration 1, LR1 with threshold 0.6: Accuracy = 0.911, Precision = 0.981, Recall = 0.875\n",
            "Iteration 1, LR1 with threshold 0.7: Accuracy = 0.906, Precision = 0.984, Recall = 0.864\n",
            "Iteration 2, LR1 with threshold 0.5: Accuracy = 0.943, Precision = 0.952, Recall = 0.957\n",
            "Iteration 2, LR1 with threshold 0.3: Accuracy = 0.941, Precision = 0.942, Recall = 0.966\n",
            "Iteration 2, LR1 with threshold 0.4: Accuracy = 0.941, Precision = 0.944, Recall = 0.963\n",
            "Iteration 2, LR1 with threshold 0.6: Accuracy = 0.941, Precision = 0.954, Recall = 0.952\n",
            "Iteration 2, LR1 with threshold 0.7: Accuracy = 0.938, Precision = 0.957, Recall = 0.943\n",
            "Iteration 3, LR1 with threshold 0.5: Accuracy = 0.881, Precision = 0.997, Recall = 0.812\n",
            "Iteration 3, LR1 with threshold 0.3: Accuracy = 0.899, Precision = 0.987, Recall = 0.849\n",
            "Iteration 3, LR1 with threshold 0.4: Accuracy = 0.893, Precision = 0.993, Recall = 0.835\n",
            "Iteration 3, LR1 with threshold 0.6: Accuracy = 0.872, Precision = 0.996, Recall = 0.798\n",
            "Iteration 3, LR1 with threshold 0.7: Accuracy = 0.865, Precision = 1.000, Recall = 0.784\n",
            "Iteration 4, LR1 with threshold 0.5: Accuracy = 0.940, Precision = 0.954, Recall = 0.949\n",
            "Iteration 4, LR1 with threshold 0.3: Accuracy = 0.941, Precision = 0.944, Recall = 0.963\n",
            "Iteration 4, LR1 with threshold 0.4: Accuracy = 0.943, Precision = 0.952, Recall = 0.957\n",
            "Iteration 4, LR1 with threshold 0.6: Accuracy = 0.940, Precision = 0.957, Recall = 0.946\n",
            "Iteration 4, LR1 with threshold 0.7: Accuracy = 0.929, Precision = 0.956, Recall = 0.929\n",
            "Iteration 5, LR1 with threshold 0.5: Accuracy = 0.943, Precision = 0.949, Recall = 0.960\n",
            "Iteration 5, LR1 with threshold 0.3: Accuracy = 0.934, Precision = 0.929, Recall = 0.969\n",
            "Iteration 5, LR1 with threshold 0.4: Accuracy = 0.940, Precision = 0.939, Recall = 0.966\n",
            "Iteration 5, LR1 with threshold 0.6: Accuracy = 0.941, Precision = 0.952, Recall = 0.955\n",
            "Iteration 5, LR1 with threshold 0.7: Accuracy = 0.940, Precision = 0.954, Recall = 0.949\n",
            "Iteration 6, LR1 with threshold 0.5: Accuracy = 0.917, Precision = 0.966, Recall = 0.898\n",
            "Iteration 6, LR1 with threshold 0.3: Accuracy = 0.934, Precision = 0.962, Recall = 0.932\n",
            "Iteration 6, LR1 with threshold 0.4: Accuracy = 0.924, Precision = 0.961, Recall = 0.915\n",
            "Iteration 6, LR1 with threshold 0.6: Accuracy = 0.917, Precision = 0.981, Recall = 0.884\n",
            "Iteration 6, LR1 with threshold 0.7: Accuracy = 0.906, Precision = 0.981, Recall = 0.866\n",
            "Iteration 7, LR1 with threshold 0.5: Accuracy = 0.938, Precision = 0.949, Recall = 0.952\n",
            "Iteration 7, LR1 with threshold 0.3: Accuracy = 0.940, Precision = 0.937, Recall = 0.969\n",
            "Iteration 7, LR1 with threshold 0.4: Accuracy = 0.941, Precision = 0.947, Recall = 0.960\n",
            "Iteration 7, LR1 with threshold 0.6: Accuracy = 0.938, Precision = 0.954, Recall = 0.946\n",
            "Iteration 7, LR1 with threshold 0.7: Accuracy = 0.941, Precision = 0.960, Recall = 0.946\n",
            "Iteration 8, LR1 with threshold 0.5: Accuracy = 0.924, Precision = 0.903, Recall = 0.983\n",
            "Iteration 8, LR1 with threshold 0.3: Accuracy = 0.924, Precision = 0.899, Recall = 0.989\n",
            "Iteration 8, LR1 with threshold 0.4: Accuracy = 0.925, Precision = 0.904, Recall = 0.986\n",
            "Iteration 8, LR1 with threshold 0.6: Accuracy = 0.931, Precision = 0.915, Recall = 0.980\n",
            "Iteration 8, LR1 with threshold 0.7: Accuracy = 0.936, Precision = 0.927, Recall = 0.974\n",
            "Iteration 9, LR1 with threshold 0.5: Accuracy = 0.927, Precision = 0.906, Recall = 0.986\n",
            "Iteration 9, LR1 with threshold 0.3: Accuracy = 0.918, Precision = 0.892, Recall = 0.989\n",
            "Iteration 9, LR1 with threshold 0.4: Accuracy = 0.924, Precision = 0.899, Recall = 0.989\n",
            "Iteration 9, LR1 with threshold 0.6: Accuracy = 0.927, Precision = 0.908, Recall = 0.983\n",
            "Iteration 9, LR1 with threshold 0.7: Accuracy = 0.925, Precision = 0.910, Recall = 0.977\n",
            "Iteration 10, LR1 with threshold 0.5: Accuracy = 0.931, Precision = 0.962, Recall = 0.926\n",
            "Iteration 10, LR1 with threshold 0.3: Accuracy = 0.940, Precision = 0.957, Recall = 0.946\n",
            "Iteration 10, LR1 with threshold 0.4: Accuracy = 0.938, Precision = 0.959, Recall = 0.940\n",
            "Iteration 10, LR1 with threshold 0.6: Accuracy = 0.922, Precision = 0.967, Recall = 0.906\n",
            "Iteration 10, LR1 with threshold 0.7: Accuracy = 0.918, Precision = 0.978, Recall = 0.889\n",
            "Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.92575488 0.93108348 0.93055062 0.92397869 0.92042629]\n",
            "Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.95106874 0.94114003 0.94720544 0.95656493 0.96065837]\n",
            "Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.93125    0.95113636 0.94346591 0.92244318 0.91221591]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LR2"
      ],
      "metadata": {
        "id": "QudqilMFcPM1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch Gradient Descent With Different Learning Rates (Alpha)"
      ],
      "metadata": {
        "id": "2hK9NFspSeTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = np.zeros((10, 5))\n",
        "precisions = np.zeros((10, 5))\n",
        "recalls = np.zeros((10, 5))\n",
        "\n",
        "for i in range(10):\n",
        "    lr2 = LogisticRegression(alpha=0.01)\n",
        "    theta2, cost_history2 = lr2.batch_gradient_descent(X.astype(float), y.astype(float))\n",
        "    thresholds = [0.5, 0.3, 0.4, 0.6, 0.7]\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = lr2.predict(X, theta2, threshold=threshold)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        precision = np.sum((y_pred == 1) & (y == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y == 1)) / np.sum(y == 1)\n",
        "        accuracies[i, j] = accuracy\n",
        "        precisions[i, j] = precision\n",
        "        recalls[i, j] = recall\n",
        "        print(f\"Iteration {i+1}, LR2 with threshold {threshold}: Accuracy = {accuracy:.3f}, Precision = {precision:.3f}, Recall = {recall:.3f}\")\n",
        "\n",
        "print(f\"Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(accuracies, axis=0)}\")\n",
        "print(f\"Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(precisions, axis=0)}\")\n",
        "print(f\"Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(recalls, axis=0)}\")"
      ],
      "metadata": {
        "id": "x36gfbhsb7X1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c9b0aa-620d-4ae2-d0e4-9766c4bcfa75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 1, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 1, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 1, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 1, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 2, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 2, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 2, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 2, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 2, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 3, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 3, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 3, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 3, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 3, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 4, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 4, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 4, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 4, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 4, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 5, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 5, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 5, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 5, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 5, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 6, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 6, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 6, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 6, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 6, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 7, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 7, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 7, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 7, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 7, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 8, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 8, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 8, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 8, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 8, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 9, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 9, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 9, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 9, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 9, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 10, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 10, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 10, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 10, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 10, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.98769772 0.98418278 0.98769772 0.98418278 0.97539543]\n",
            "Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.98611111 0.97540984 0.98076923 0.98603352 0.98860399]\n",
            "Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.99439776 1.         1.         0.98879552 0.9719888 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = np.zeros((10, 5))\n",
        "precisions = np.zeros((10, 5))\n",
        "recalls = np.zeros((10, 5))\n",
        "\n",
        "for i in range(10):\n",
        "    lr2 = LogisticRegression(alpha=0.001)\n",
        "    theta2, cost_history2 = lr2.batch_gradient_descent(X.astype(float), y.astype(float))\n",
        "    thresholds = [0.5, 0.3, 0.4, 0.6, 0.7]\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = lr2.predict(X, theta2, threshold=threshold)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        precision = np.sum((y_pred == 1) & (y == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y == 1)) / np.sum(y == 1)\n",
        "        accuracies[i, j] = accuracy\n",
        "        precisions[i, j] = precision\n",
        "        recalls[i, j] = recall\n",
        "        print(f\"Iteration {i+1}, LR2 with threshold {threshold}: Accuracy = {accuracy:.3f}, Precision = {precision:.3f}, Recall = {recall:.3f}\")\n",
        "\n",
        "print(f\"Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(accuracies, axis=0)}\")\n",
        "print(f\"Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(precisions, axis=0)}\")\n",
        "print(f\"Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(recalls, axis=0)}\")"
      ],
      "metadata": {
        "id": "Wjar4MLK_xwT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bcfacc1-ced7-44b8-d6fe-4c152e322f63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 1, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 1, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 1, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 1, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Iteration 2, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 2, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 2, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 2, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 2, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Iteration 3, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 3, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 3, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 3, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 3, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Iteration 4, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 4, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 4, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 4, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 4, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Iteration 5, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 5, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 5, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 5, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 5, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Iteration 6, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 6, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 6, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 6, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 6, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Iteration 7, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 7, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 7, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 7, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 7, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Iteration 8, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 8, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 8, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 8, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 8, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Iteration 9, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 9, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 9, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 9, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 9, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Iteration 10, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 10, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 10, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 10, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 10, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.98418278 0.95957821 0.97363796 0.97539543 0.96485062]\n",
            "Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.98066298 0.93947368 0.96216216 0.98583569 0.9884058 ]\n",
            "Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.99439776 1.         0.99719888 0.97478992 0.95518207]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = np.zeros((10, 5))\n",
        "precisions = np.zeros((10, 5))\n",
        "recalls = np.zeros((10, 5))\n",
        "\n",
        "for i in range(10):\n",
        "    lr2 = LogisticRegression(alpha=0.0001)\n",
        "    theta2, cost_history2 = lr2.batch_gradient_descent(X.astype(float), y.astype(float))\n",
        "    thresholds = [0.5, 0.3, 0.4, 0.6, 0.7]\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = lr2.predict(X, theta2, threshold=threshold)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        precision = np.sum((y_pred == 1) & (y == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y == 1)) / np.sum(y == 1)\n",
        "        accuracies[i, j] = accuracy\n",
        "        precisions[i, j] = precision\n",
        "        recalls[i, j] = recall\n",
        "        print(f\"Iteration {i+1}, LR2 with threshold {threshold}: Accuracy = {accuracy:.3f}, Precision = {precision:.3f}, Recall = {recall:.3f}\")\n",
        "\n",
        "print(f\"Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(accuracies, axis=0)}\")\n",
        "print(f\"Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(precisions, axis=0)}\")\n",
        "print(f\"Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(recalls, axis=0)}\")"
      ],
      "metadata": {
        "id": "47F-jjyg_yVi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63ffa76d-3044-4f8c-901d-8ac8c1acb0bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 1, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 1, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 1, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 1, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Iteration 2, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 2, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 2, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 2, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 2, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Iteration 3, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 3, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 3, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 3, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 3, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Iteration 4, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 4, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 4, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 4, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 4, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Iteration 5, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 5, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 5, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 5, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 5, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Iteration 6, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 6, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 6, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 6, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 6, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Iteration 7, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 7, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 7, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 7, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 7, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Iteration 8, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 8, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 8, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 8, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 8, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Iteration 9, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 9, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 9, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 9, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 9, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Iteration 10, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 10, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 10, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 10, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 10, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.96309315 0.93848858 0.95079086 0.94200351 0.89630931]\n",
            "Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.96927374 0.91071429 0.93175853 0.98502994 0.99013158]\n",
            "Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.9719888  1.         0.99439776 0.92156863 0.84313725]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Mini Batch Gradient Descent With Different Learning Rates (Alpha)"
      ],
      "metadata": {
        "id": "Iw5wE24dSkSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = np.zeros((10, 5))\n",
        "precisions = np.zeros((10, 5))\n",
        "recalls = np.zeros((10, 5))\n",
        "\n",
        "for i in range(10):\n",
        "    lr2 = LogisticRegression(alpha=0.01)\n",
        "    theta2, cost_history2 = lr2.mini_batch_gradient_descent(X.astype(float), y.astype(float))\n",
        "    thresholds = [0.5, 0.3, 0.4, 0.6, 0.7]\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = lr2.predict(X, theta2, threshold=threshold)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        precision = np.sum((y_pred == 1) & (y == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y == 1)) / np.sum(y == 1)\n",
        "        accuracies[i, j] = accuracy\n",
        "        precisions[i, j] = precision\n",
        "        recalls[i, j] = recall\n",
        "        print(f\"Iteration {i+1}, LR2 with threshold {threshold}: Accuracy = {accuracy:.3f}, Precision = {precision:.3f}, Recall = {recall:.3f}\")\n",
        "\n",
        "print(f\"Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(accuracies, axis=0)}\")\n",
        "print(f\"Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(precisions, axis=0)}\")\n",
        "print(f\"Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(recalls, axis=0)}\")"
      ],
      "metadata": {
        "id": "XX3k_IzgSvoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ba4ff2-8799-485d-9e15-06084aaa4baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 1, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 1, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 1, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 1, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 2, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 2, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 2, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 2, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 2, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 3, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 3, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 3, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 3, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 3, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 4, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 4, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 4, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 4, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 4, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 5, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 5, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 5, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 5, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 5, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 6, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 6, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 6, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 6, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 6, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 7, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 7, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 7, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 7, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 7, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 8, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 8, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 8, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 8, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 8, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 9, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 9, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 9, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 9, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 9, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 10, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 10, LR2 with threshold 0.3: Accuracy = 0.984, Precision = 0.975, Recall = 1.000\n",
            "Iteration 10, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 10, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.986, Recall = 0.989\n",
            "Iteration 10, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.98769772 0.98418278 0.98769772 0.98418278 0.97539543]\n",
            "Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.98611111 0.97540984 0.98076923 0.98603352 0.98860399]\n",
            "Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.99439776 1.         1.         0.98879552 0.9719888 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = np.zeros((10, 5))\n",
        "precisions = np.zeros((10, 5))\n",
        "recalls = np.zeros((10, 5))\n",
        "\n",
        "for i in range(10):\n",
        "    lr2 = LogisticRegression(alpha=0.001)\n",
        "    theta2, cost_history2 = lr2.mini_batch_gradient_descent(X.astype(float), y.astype(float))\n",
        "    thresholds = [0.5, 0.3, 0.4, 0.6, 0.7]\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = lr2.predict(X, theta2, threshold=threshold)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        precision = np.sum((y_pred == 1) & (y == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y == 1)) / np.sum(y == 1)\n",
        "        accuracies[i, j] = accuracy\n",
        "        precisions[i, j] = precision\n",
        "        recalls[i, j] = recall\n",
        "        print(f\"Iteration {i+1}, LR2 with threshold {threshold}: Accuracy = {accuracy:.3f}, Precision = {precision:.3f}, Recall = {recall:.3f}\")\n",
        "\n",
        "print(f\"Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(accuracies, axis=0)}\")\n",
        "print(f\"Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(precisions, axis=0)}\")\n",
        "print(f\"Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(recalls, axis=0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxHX7o2xlU5t",
        "outputId": "5131c3ff-6a65-4e9d-f368-434da3653462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 1, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 1, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 1, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 1, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Iteration 2, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 2, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 2, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 2, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 2, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Iteration 3, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 3, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 3, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 3, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 3, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Iteration 4, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 4, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 4, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 4, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 4, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Iteration 5, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 5, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 5, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 5, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 5, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Iteration 6, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 6, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 6, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 6, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 6, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Iteration 7, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 7, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 7, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 7, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 7, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Iteration 8, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 8, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 8, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 8, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 8, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Iteration 9, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 9, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 9, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 9, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 9, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Iteration 10, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 10, LR2 with threshold 0.3: Accuracy = 0.960, Precision = 0.939, Recall = 1.000\n",
            "Iteration 10, LR2 with threshold 0.4: Accuracy = 0.974, Precision = 0.962, Recall = 0.997\n",
            "Iteration 10, LR2 with threshold 0.6: Accuracy = 0.975, Precision = 0.986, Recall = 0.975\n",
            "Iteration 10, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.988, Recall = 0.955\n",
            "Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.98418278 0.95957821 0.97363796 0.97539543 0.96485062]\n",
            "Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.98066298 0.93947368 0.96216216 0.98583569 0.9884058 ]\n",
            "Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.99439776 1.         0.99719888 0.97478992 0.95518207]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = np.zeros((10, 5))\n",
        "precisions = np.zeros((10, 5))\n",
        "recalls = np.zeros((10, 5))\n",
        "\n",
        "for i in range(10):\n",
        "    lr2 = LogisticRegression(alpha=0.0001)\n",
        "    theta2, cost_history2 = lr2.mini_batch_gradient_descent(X.astype(float), y.astype(float))\n",
        "    thresholds = [0.5, 0.3, 0.4, 0.6, 0.7]\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = lr2.predict(X, theta2, threshold=threshold)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        precision = np.sum((y_pred == 1) & (y == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y == 1)) / np.sum(y == 1)\n",
        "        accuracies[i, j] = accuracy\n",
        "        precisions[i, j] = precision\n",
        "        recalls[i, j] = recall\n",
        "        print(f\"Iteration {i+1}, LR2 with threshold {threshold}: Accuracy = {accuracy:.3f}, Precision = {precision:.3f}, Recall = {recall:.3f}\")\n",
        "\n",
        "print(f\"Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(accuracies, axis=0)}\")\n",
        "print(f\"Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(precisions, axis=0)}\")\n",
        "print(f\"Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(recalls, axis=0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA3b2Km6lg8t",
        "outputId": "8024d035-6811-4765-8122-79e8f0b79c1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 1, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 1, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 1, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 1, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Iteration 2, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 2, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 2, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 2, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 2, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Iteration 3, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 3, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 3, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 3, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 3, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Iteration 4, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 4, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 4, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 4, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 4, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Iteration 5, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 5, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 5, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 5, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 5, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Iteration 6, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 6, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 6, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 6, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 6, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Iteration 7, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 7, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 7, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 7, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 7, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Iteration 8, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 8, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 8, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 8, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 8, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Iteration 9, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 9, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 9, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 9, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 9, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Iteration 10, LR2 with threshold 0.5: Accuracy = 0.963, Precision = 0.969, Recall = 0.972\n",
            "Iteration 10, LR2 with threshold 0.3: Accuracy = 0.938, Precision = 0.911, Recall = 1.000\n",
            "Iteration 10, LR2 with threshold 0.4: Accuracy = 0.951, Precision = 0.932, Recall = 0.994\n",
            "Iteration 10, LR2 with threshold 0.6: Accuracy = 0.942, Precision = 0.985, Recall = 0.922\n",
            "Iteration 10, LR2 with threshold 0.7: Accuracy = 0.896, Precision = 0.990, Recall = 0.843\n",
            "Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.96309315 0.93848858 0.95079086 0.94200351 0.89630931]\n",
            "Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.96927374 0.91071429 0.93175853 0.98502994 0.99013158]\n",
            "Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.9719888  1.         0.99439776 0.92156863 0.84313725]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stochaistic Gradient Descent With Different Learning Rates (Alpha)"
      ],
      "metadata": {
        "id": "gQAWSUo8ln-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = np.zeros((10, 5))\n",
        "precisions = np.zeros((10, 5))\n",
        "recalls = np.zeros((10, 5))\n",
        "\n",
        "for i in range(10):\n",
        "    lr2 = LogisticRegression(alpha=0.01)\n",
        "    theta2, cost_history2 = lr2.stochastic_gradient_descent(X.astype(float), y.astype(float))\n",
        "    thresholds = [0.5, 0.3, 0.4, 0.6, 0.7]\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = lr2.predict(X, theta2, threshold=threshold)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        precision = np.sum((y_pred == 1) & (y == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y == 1)) / np.sum(y == 1)\n",
        "        accuracies[i, j] = accuracy\n",
        "        precisions[i, j] = precision\n",
        "        recalls[i, j] = recall\n",
        "        print(f\"Iteration {i+1}, LR2 with threshold {threshold}: Accuracy = {accuracy:.3f}, Precision = {precision:.3f}, Recall = {recall:.3f}\")\n",
        "\n",
        "print(f\"Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(accuracies, axis=0)}\")\n",
        "print(f\"Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(precisions, axis=0)}\")\n",
        "print(f\"Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(recalls, axis=0)}\")"
      ],
      "metadata": {
        "id": "WsdbJ2oWSwXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f97203b-c448-4738-bdea-1d8530f9785d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, LR2 with threshold 0.5: Accuracy = 0.991, Precision = 0.989, Recall = 0.997\n",
            "Iteration 1, LR2 with threshold 0.3: Accuracy = 0.989, Precision = 0.983, Recall = 1.000\n",
            "Iteration 1, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.983, Recall = 0.997\n",
            "Iteration 1, LR2 with threshold 0.6: Accuracy = 0.982, Precision = 0.989, Recall = 0.983\n",
            "Iteration 1, LR2 with threshold 0.7: Accuracy = 0.979, Precision = 0.989, Recall = 0.978\n",
            "Iteration 2, LR2 with threshold 0.5: Accuracy = 0.991, Precision = 0.989, Recall = 0.997\n",
            "Iteration 2, LR2 with threshold 0.3: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 2, LR2 with threshold 0.4: Accuracy = 0.989, Precision = 0.986, Recall = 0.997\n",
            "Iteration 2, LR2 with threshold 0.6: Accuracy = 0.986, Precision = 0.989, Recall = 0.989\n",
            "Iteration 2, LR2 with threshold 0.7: Accuracy = 0.981, Precision = 0.989, Recall = 0.980\n",
            "Iteration 3, LR2 with threshold 0.5: Accuracy = 0.991, Precision = 0.989, Recall = 0.997\n",
            "Iteration 3, LR2 with threshold 0.3: Accuracy = 0.989, Precision = 0.983, Recall = 1.000\n",
            "Iteration 3, LR2 with threshold 0.4: Accuracy = 0.989, Precision = 0.986, Recall = 0.997\n",
            "Iteration 3, LR2 with threshold 0.6: Accuracy = 0.988, Precision = 0.989, Recall = 0.992\n",
            "Iteration 3, LR2 with threshold 0.7: Accuracy = 0.981, Precision = 0.989, Recall = 0.980\n",
            "Iteration 4, LR2 with threshold 0.5: Accuracy = 0.989, Precision = 0.986, Recall = 0.997\n",
            "Iteration 4, LR2 with threshold 0.3: Accuracy = 0.989, Precision = 0.983, Recall = 1.000\n",
            "Iteration 4, LR2 with threshold 0.4: Accuracy = 0.989, Precision = 0.986, Recall = 0.997\n",
            "Iteration 4, LR2 with threshold 0.6: Accuracy = 0.986, Precision = 0.989, Recall = 0.989\n",
            "Iteration 4, LR2 with threshold 0.7: Accuracy = 0.981, Precision = 0.989, Recall = 0.980\n",
            "Iteration 5, LR2 with threshold 0.5: Accuracy = 0.991, Precision = 0.989, Recall = 0.997\n",
            "Iteration 5, LR2 with threshold 0.3: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 5, LR2 with threshold 0.4: Accuracy = 0.989, Precision = 0.986, Recall = 0.997\n",
            "Iteration 5, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.989, Recall = 0.986\n",
            "Iteration 5, LR2 with threshold 0.7: Accuracy = 0.981, Precision = 0.989, Recall = 0.980\n",
            "Iteration 6, LR2 with threshold 0.5: Accuracy = 0.989, Precision = 0.986, Recall = 0.997\n",
            "Iteration 6, LR2 with threshold 0.3: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 6, LR2 with threshold 0.4: Accuracy = 0.989, Precision = 0.986, Recall = 0.997\n",
            "Iteration 6, LR2 with threshold 0.6: Accuracy = 0.986, Precision = 0.989, Recall = 0.989\n",
            "Iteration 6, LR2 with threshold 0.7: Accuracy = 0.982, Precision = 0.989, Recall = 0.983\n",
            "Iteration 7, LR2 with threshold 0.5: Accuracy = 0.989, Precision = 0.986, Recall = 0.997\n",
            "Iteration 7, LR2 with threshold 0.3: Accuracy = 0.989, Precision = 0.983, Recall = 1.000\n",
            "Iteration 7, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.983, Recall = 0.997\n",
            "Iteration 7, LR2 with threshold 0.6: Accuracy = 0.986, Precision = 0.989, Recall = 0.989\n",
            "Iteration 7, LR2 with threshold 0.7: Accuracy = 0.981, Precision = 0.989, Recall = 0.980\n",
            "Iteration 8, LR2 with threshold 0.5: Accuracy = 0.991, Precision = 0.989, Recall = 0.997\n",
            "Iteration 8, LR2 with threshold 0.3: Accuracy = 0.988, Precision = 0.981, Recall = 1.000\n",
            "Iteration 8, LR2 with threshold 0.4: Accuracy = 0.988, Precision = 0.983, Recall = 0.997\n",
            "Iteration 8, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.989, Recall = 0.986\n",
            "Iteration 8, LR2 with threshold 0.7: Accuracy = 0.981, Precision = 0.989, Recall = 0.980\n",
            "Iteration 9, LR2 with threshold 0.5: Accuracy = 0.991, Precision = 0.989, Recall = 0.997\n",
            "Iteration 9, LR2 with threshold 0.3: Accuracy = 0.989, Precision = 0.983, Recall = 1.000\n",
            "Iteration 9, LR2 with threshold 0.4: Accuracy = 0.989, Precision = 0.986, Recall = 0.997\n",
            "Iteration 9, LR2 with threshold 0.6: Accuracy = 0.984, Precision = 0.989, Recall = 0.986\n",
            "Iteration 9, LR2 with threshold 0.7: Accuracy = 0.981, Precision = 0.989, Recall = 0.980\n",
            "Iteration 10, LR2 with threshold 0.5: Accuracy = 0.989, Precision = 0.986, Recall = 0.997\n",
            "Iteration 10, LR2 with threshold 0.3: Accuracy = 0.989, Precision = 0.983, Recall = 1.000\n",
            "Iteration 10, LR2 with threshold 0.4: Accuracy = 0.989, Precision = 0.986, Recall = 0.997\n",
            "Iteration 10, LR2 with threshold 0.6: Accuracy = 0.986, Precision = 0.989, Recall = 0.989\n",
            "Iteration 10, LR2 with threshold 0.7: Accuracy = 0.981, Precision = 0.989, Recall = 0.980\n",
            "Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.99050967 0.9887522  0.98892794 0.98523726 0.98066784]\n",
            "Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.98779317 0.98239034 0.98533233 0.98878289 0.98870055]\n",
            "Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.99719888 1.         0.99719888 0.98767507 0.98039216]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = np.zeros((10, 5))\n",
        "precisions = np.zeros((10, 5))\n",
        "recalls = np.zeros((10, 5))\n",
        "\n",
        "for i in range(10):\n",
        "    lr2 = LogisticRegression(alpha=0.001)\n",
        "    theta2, cost_history2 = lr2.stochastic_gradient_descent(X.astype(float), y.astype(float))\n",
        "    thresholds = [0.5, 0.3, 0.4, 0.6, 0.7]\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = lr2.predict(X, theta2, threshold=threshold)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        precision = np.sum((y_pred == 1) & (y == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y == 1)) / np.sum(y == 1)\n",
        "        accuracies[i, j] = accuracy\n",
        "        precisions[i, j] = precision\n",
        "        recalls[i, j] = recall\n",
        "        print(f\"Iteration {i+1}, LR2 with threshold {threshold}: Accuracy = {accuracy:.3f}, Precision = {precision:.3f}, Recall = {recall:.3f}\")\n",
        "\n",
        "print(f\"Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(accuracies, axis=0)}\")\n",
        "print(f\"Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(precisions, axis=0)}\")\n",
        "print(f\"Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(recalls, axis=0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlV48aSJmE8n",
        "outputId": "4eca2d5d-d0d8-4098-e84f-dfd526c5f437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 1, LR2 with threshold 0.3: Accuracy = 0.986, Precision = 0.978, Recall = 1.000\n",
            "Iteration 1, LR2 with threshold 0.4: Accuracy = 0.989, Precision = 0.983, Recall = 1.000\n",
            "Iteration 1, LR2 with threshold 0.6: Accuracy = 0.986, Precision = 0.986, Recall = 0.992\n",
            "Iteration 1, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 2, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 2, LR2 with threshold 0.3: Accuracy = 0.986, Precision = 0.978, Recall = 1.000\n",
            "Iteration 2, LR2 with threshold 0.4: Accuracy = 0.989, Precision = 0.983, Recall = 1.000\n",
            "Iteration 2, LR2 with threshold 0.6: Accuracy = 0.986, Precision = 0.986, Recall = 0.992\n",
            "Iteration 2, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 3, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 3, LR2 with threshold 0.3: Accuracy = 0.986, Precision = 0.978, Recall = 1.000\n",
            "Iteration 3, LR2 with threshold 0.4: Accuracy = 0.989, Precision = 0.983, Recall = 1.000\n",
            "Iteration 3, LR2 with threshold 0.6: Accuracy = 0.986, Precision = 0.986, Recall = 0.992\n",
            "Iteration 3, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 4, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 4, LR2 with threshold 0.3: Accuracy = 0.986, Precision = 0.978, Recall = 1.000\n",
            "Iteration 4, LR2 with threshold 0.4: Accuracy = 0.989, Precision = 0.983, Recall = 1.000\n",
            "Iteration 4, LR2 with threshold 0.6: Accuracy = 0.986, Precision = 0.986, Recall = 0.992\n",
            "Iteration 4, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 5, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 5, LR2 with threshold 0.3: Accuracy = 0.986, Precision = 0.978, Recall = 1.000\n",
            "Iteration 5, LR2 with threshold 0.4: Accuracy = 0.989, Precision = 0.983, Recall = 1.000\n",
            "Iteration 5, LR2 with threshold 0.6: Accuracy = 0.986, Precision = 0.986, Recall = 0.992\n",
            "Iteration 5, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 6, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 6, LR2 with threshold 0.3: Accuracy = 0.986, Precision = 0.978, Recall = 1.000\n",
            "Iteration 6, LR2 with threshold 0.4: Accuracy = 0.989, Precision = 0.983, Recall = 1.000\n",
            "Iteration 6, LR2 with threshold 0.6: Accuracy = 0.986, Precision = 0.986, Recall = 0.992\n",
            "Iteration 6, LR2 with threshold 0.7: Accuracy = 0.977, Precision = 0.989, Recall = 0.975\n",
            "Iteration 7, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 7, LR2 with threshold 0.3: Accuracy = 0.986, Precision = 0.978, Recall = 1.000\n",
            "Iteration 7, LR2 with threshold 0.4: Accuracy = 0.989, Precision = 0.983, Recall = 1.000\n",
            "Iteration 7, LR2 with threshold 0.6: Accuracy = 0.986, Precision = 0.986, Recall = 0.992\n",
            "Iteration 7, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Iteration 8, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 8, LR2 with threshold 0.3: Accuracy = 0.986, Precision = 0.978, Recall = 1.000\n",
            "Iteration 8, LR2 with threshold 0.4: Accuracy = 0.989, Precision = 0.983, Recall = 1.000\n",
            "Iteration 8, LR2 with threshold 0.6: Accuracy = 0.986, Precision = 0.986, Recall = 0.992\n",
            "Iteration 8, LR2 with threshold 0.7: Accuracy = 0.979, Precision = 0.989, Recall = 0.978\n",
            "Iteration 9, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 9, LR2 with threshold 0.3: Accuracy = 0.986, Precision = 0.978, Recall = 1.000\n",
            "Iteration 9, LR2 with threshold 0.4: Accuracy = 0.989, Precision = 0.983, Recall = 1.000\n",
            "Iteration 9, LR2 with threshold 0.6: Accuracy = 0.986, Precision = 0.986, Recall = 0.992\n",
            "Iteration 9, LR2 with threshold 0.7: Accuracy = 0.977, Precision = 0.989, Recall = 0.975\n",
            "Iteration 10, LR2 with threshold 0.5: Accuracy = 0.988, Precision = 0.986, Recall = 0.994\n",
            "Iteration 10, LR2 with threshold 0.3: Accuracy = 0.986, Precision = 0.978, Recall = 1.000\n",
            "Iteration 10, LR2 with threshold 0.4: Accuracy = 0.989, Precision = 0.983, Recall = 1.000\n",
            "Iteration 10, LR2 with threshold 0.6: Accuracy = 0.986, Precision = 0.986, Recall = 0.992\n",
            "Iteration 10, LR2 with threshold 0.7: Accuracy = 0.975, Precision = 0.989, Recall = 0.972\n",
            "Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.98769772 0.98594025 0.98945518 0.98594025 0.97609842]\n",
            "Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.98611111 0.97808219 0.98347107 0.98607242 0.98861692]\n",
            "Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.99439776 1.         1.         0.99159664 0.97310924]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = np.zeros((10, 5))\n",
        "precisions = np.zeros((10, 5))\n",
        "recalls = np.zeros((10, 5))\n",
        "\n",
        "for i in range(10):\n",
        "    lr2 = LogisticRegression(alpha=0.0001)\n",
        "    theta2, cost_history2 = lr2.stochastic_gradient_descent(X.astype(float), y.astype(float))\n",
        "    thresholds = [0.5, 0.3, 0.4, 0.6, 0.7]\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = lr2.predict(X, theta2, threshold=threshold)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        precision = np.sum((y_pred == 1) & (y == 1)) / np.sum(y_pred == 1)\n",
        "        recall = np.sum((y_pred == 1) & (y == 1)) / np.sum(y == 1)\n",
        "        accuracies[i, j] = accuracy\n",
        "        precisions[i, j] = precision\n",
        "        recalls[i, j] = recall\n",
        "        print(f\"Iteration {i+1}, LR2 with threshold {threshold}: Accuracy = {accuracy:.3f}, Precision = {precision:.3f}, Recall = {recall:.3f}\")\n",
        "    \n",
        "print(f\"Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(accuracies, axis=0)}\")\n",
        "print(f\"Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(precisions, axis=0)}\")\n",
        "print(f\"Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: {np.mean(recalls, axis=0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg8z_YrpmMnW",
        "outputId": "c3cd8afe-d8db-4e5f-e1b7-e5b03827e148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 1, LR2 with threshold 0.3: Accuracy = 0.967, Precision = 0.949, Recall = 1.000\n",
            "Iteration 1, LR2 with threshold 0.4: Accuracy = 0.977, Precision = 0.967, Recall = 0.997\n",
            "Iteration 1, LR2 with threshold 0.6: Accuracy = 0.979, Precision = 0.986, Recall = 0.980\n",
            "Iteration 1, LR2 with threshold 0.7: Accuracy = 0.967, Precision = 0.988, Recall = 0.958\n",
            "Iteration 2, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 2, LR2 with threshold 0.3: Accuracy = 0.967, Precision = 0.949, Recall = 1.000\n",
            "Iteration 2, LR2 with threshold 0.4: Accuracy = 0.977, Precision = 0.967, Recall = 0.997\n",
            "Iteration 2, LR2 with threshold 0.6: Accuracy = 0.979, Precision = 0.986, Recall = 0.980\n",
            "Iteration 2, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.986, Recall = 0.958\n",
            "Iteration 3, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 3, LR2 with threshold 0.3: Accuracy = 0.967, Precision = 0.949, Recall = 1.000\n",
            "Iteration 3, LR2 with threshold 0.4: Accuracy = 0.977, Precision = 0.967, Recall = 0.997\n",
            "Iteration 3, LR2 with threshold 0.6: Accuracy = 0.979, Precision = 0.986, Recall = 0.980\n",
            "Iteration 3, LR2 with threshold 0.7: Accuracy = 0.967, Precision = 0.988, Recall = 0.958\n",
            "Iteration 4, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 4, LR2 with threshold 0.3: Accuracy = 0.967, Precision = 0.949, Recall = 1.000\n",
            "Iteration 4, LR2 with threshold 0.4: Accuracy = 0.977, Precision = 0.967, Recall = 0.997\n",
            "Iteration 4, LR2 with threshold 0.6: Accuracy = 0.979, Precision = 0.986, Recall = 0.980\n",
            "Iteration 4, LR2 with threshold 0.7: Accuracy = 0.967, Precision = 0.988, Recall = 0.958\n",
            "Iteration 5, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 5, LR2 with threshold 0.3: Accuracy = 0.967, Precision = 0.949, Recall = 1.000\n",
            "Iteration 5, LR2 with threshold 0.4: Accuracy = 0.977, Precision = 0.967, Recall = 0.997\n",
            "Iteration 5, LR2 with threshold 0.6: Accuracy = 0.979, Precision = 0.986, Recall = 0.980\n",
            "Iteration 5, LR2 with threshold 0.7: Accuracy = 0.967, Precision = 0.988, Recall = 0.958\n",
            "Iteration 6, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 6, LR2 with threshold 0.3: Accuracy = 0.967, Precision = 0.949, Recall = 1.000\n",
            "Iteration 6, LR2 with threshold 0.4: Accuracy = 0.977, Precision = 0.967, Recall = 0.997\n",
            "Iteration 6, LR2 with threshold 0.6: Accuracy = 0.979, Precision = 0.986, Recall = 0.980\n",
            "Iteration 6, LR2 with threshold 0.7: Accuracy = 0.965, Precision = 0.986, Recall = 0.958\n",
            "Iteration 7, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 7, LR2 with threshold 0.3: Accuracy = 0.967, Precision = 0.949, Recall = 1.000\n",
            "Iteration 7, LR2 with threshold 0.4: Accuracy = 0.977, Precision = 0.967, Recall = 0.997\n",
            "Iteration 7, LR2 with threshold 0.6: Accuracy = 0.979, Precision = 0.986, Recall = 0.980\n",
            "Iteration 7, LR2 with threshold 0.7: Accuracy = 0.967, Precision = 0.988, Recall = 0.958\n",
            "Iteration 8, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 8, LR2 with threshold 0.3: Accuracy = 0.967, Precision = 0.949, Recall = 1.000\n",
            "Iteration 8, LR2 with threshold 0.4: Accuracy = 0.977, Precision = 0.967, Recall = 0.997\n",
            "Iteration 8, LR2 with threshold 0.6: Accuracy = 0.979, Precision = 0.986, Recall = 0.980\n",
            "Iteration 8, LR2 with threshold 0.7: Accuracy = 0.967, Precision = 0.988, Recall = 0.958\n",
            "Iteration 9, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 9, LR2 with threshold 0.3: Accuracy = 0.967, Precision = 0.949, Recall = 1.000\n",
            "Iteration 9, LR2 with threshold 0.4: Accuracy = 0.977, Precision = 0.967, Recall = 0.997\n",
            "Iteration 9, LR2 with threshold 0.6: Accuracy = 0.979, Precision = 0.986, Recall = 0.980\n",
            "Iteration 9, LR2 with threshold 0.7: Accuracy = 0.967, Precision = 0.988, Recall = 0.958\n",
            "Iteration 10, LR2 with threshold 0.5: Accuracy = 0.984, Precision = 0.981, Recall = 0.994\n",
            "Iteration 10, LR2 with threshold 0.3: Accuracy = 0.967, Precision = 0.949, Recall = 1.000\n",
            "Iteration 10, LR2 with threshold 0.4: Accuracy = 0.977, Precision = 0.967, Recall = 0.997\n",
            "Iteration 10, LR2 with threshold 0.6: Accuracy = 0.979, Precision = 0.986, Recall = 0.980\n",
            "Iteration 10, LR2 with threshold 0.7: Accuracy = 0.967, Precision = 0.988, Recall = 0.958\n",
            "Average accuracy for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.98418278 0.96660808 0.9771529  0.97891037 0.96625659]\n",
            "Average precision for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.98066298 0.94946809 0.9673913  0.98591549 0.9878696 ]\n",
            "Average recall for 0.5, 0.3, 0.4, 0.6, 0.7 threshold: [0.99439776 1.         0.99719888 0.98039216 0.95798319]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Learning Curves"
      ],
      "metadata": {
        "id": "ssMLtbOycOqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plt.scatter([y for y in range(len(lr2.batch_gradient_descent(X.astype(float), y.astype(float))[1]))], lr2.batch_gradient_descent(X.astype(float), y.astype(float))[1], label='LR1')\n",
        "plt.title('Learning Curve')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Cost')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "WcsBdFnUb-7h",
        "outputId": "a5e9b4f2-e968-4b2b-bfe5-15523bef73e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plt.scatter([y for y in range(len(lr2.mini_batch_gradient_descent(X.astype(float), y.astype(float))[1]))], lr2.mini_batch_gradient_descent(X.astype(float), y.astype(float))[1], label='LR2')\n",
        "plt.title('Learning Curve')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Cost')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "HAJRQC_tBfZJ",
        "outputId": "61e7cbcc-fdf3-4024-94f0-1e765b097afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plt.scatter([y for y in range(len(lr2.mini_batch_gradient_descent(X.astype(float), y.astype(float))[1]))],lr2.mini_batch_gradient_descent(X.astype(float), y.astype(float))[1], label='LR3')\n",
        "plt.title('Learning Curve')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Cost')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "t8D-AkNkFcMh",
        "outputId": "a4eb957f-7db7-426e-a79e-cb49e261811e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BfDjI-vtPyAg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}